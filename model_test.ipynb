{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>EMA_12</th>\n",
       "      <th>EMA_26</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal</th>\n",
       "      <th>RSI</th>\n",
       "      <th>CCI</th>\n",
       "      <th>ADX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-03-02 00:00:00-05:00</td>\n",
       "      <td>28.865108</td>\n",
       "      <td>29.095135</td>\n",
       "      <td>28.652947</td>\n",
       "      <td>28.829374</td>\n",
       "      <td>192386800</td>\n",
       "      <td>28.829374</td>\n",
       "      <td>28.829374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.526105</td>\n",
       "      <td>56.240216</td>\n",
       "      <td>28.673114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-03-03 00:00:00-05:00</td>\n",
       "      <td>28.800338</td>\n",
       "      <td>28.925401</td>\n",
       "      <td>28.606040</td>\n",
       "      <td>28.889668</td>\n",
       "      <td>151265200</td>\n",
       "      <td>28.838650</td>\n",
       "      <td>28.833840</td>\n",
       "      <td>0.004810</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>45.526105</td>\n",
       "      <td>56.240216</td>\n",
       "      <td>28.673114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-04 00:00:00-05:00</td>\n",
       "      <td>28.831606</td>\n",
       "      <td>28.934334</td>\n",
       "      <td>28.657410</td>\n",
       "      <td>28.706539</td>\n",
       "      <td>126665200</td>\n",
       "      <td>28.818325</td>\n",
       "      <td>28.824411</td>\n",
       "      <td>-0.006085</td>\n",
       "      <td>-0.000448</td>\n",
       "      <td>45.526105</td>\n",
       "      <td>56.240216</td>\n",
       "      <td>28.673114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-03-05 00:00:00-05:00</td>\n",
       "      <td>28.715477</td>\n",
       "      <td>28.753442</td>\n",
       "      <td>28.085693</td>\n",
       "      <td>28.230856</td>\n",
       "      <td>226068400</td>\n",
       "      <td>28.727945</td>\n",
       "      <td>28.780444</td>\n",
       "      <td>-0.052498</td>\n",
       "      <td>-0.010858</td>\n",
       "      <td>45.526105</td>\n",
       "      <td>56.240216</td>\n",
       "      <td>28.673114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-03-06 00:00:00-05:00</td>\n",
       "      <td>28.675274</td>\n",
       "      <td>28.891902</td>\n",
       "      <td>28.197354</td>\n",
       "      <td>28.273285</td>\n",
       "      <td>291368400</td>\n",
       "      <td>28.657998</td>\n",
       "      <td>28.742876</td>\n",
       "      <td>-0.084879</td>\n",
       "      <td>-0.025662</td>\n",
       "      <td>45.526105</td>\n",
       "      <td>56.240216</td>\n",
       "      <td>28.673114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date       Open       High        Low      Close  \\\n",
       "0  2015-03-02 00:00:00-05:00  28.865108  29.095135  28.652947  28.829374   \n",
       "1  2015-03-03 00:00:00-05:00  28.800338  28.925401  28.606040  28.889668   \n",
       "2  2015-03-04 00:00:00-05:00  28.831606  28.934334  28.657410  28.706539   \n",
       "3  2015-03-05 00:00:00-05:00  28.715477  28.753442  28.085693  28.230856   \n",
       "4  2015-03-06 00:00:00-05:00  28.675274  28.891902  28.197354  28.273285   \n",
       "\n",
       "      Volume     EMA_12     EMA_26      MACD    Signal        RSI        CCI  \\\n",
       "0  192386800  28.829374  28.829374  0.000000  0.000000  45.526105  56.240216   \n",
       "1  151265200  28.838650  28.833840  0.004810  0.000962  45.526105  56.240216   \n",
       "2  126665200  28.818325  28.824411 -0.006085 -0.000448  45.526105  56.240216   \n",
       "3  226068400  28.727945  28.780444 -0.052498 -0.010858  45.526105  56.240216   \n",
       "4  291368400  28.657998  28.742876 -0.084879 -0.025662  45.526105  56.240216   \n",
       "\n",
       "         ADX  \n",
       "0  28.673114  \n",
       "1  28.673114  \n",
       "2  28.673114  \n",
       "3  28.673114  \n",
       "4  28.673114  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./stocks_data/AAPL_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2515, (2515, 13))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'EMA_12', 'EMA_26',\n",
       "       'MACD', 'Signal', 'RSI', 'CCI', 'ADX'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.set_index(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>EMA_12</th>\n",
       "      <th>EMA_26</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal</th>\n",
       "      <th>RSI</th>\n",
       "      <th>CCI</th>\n",
       "      <th>ADX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-02-21 00:00:00-05:00</th>\n",
       "      <td>245.949997</td>\n",
       "      <td>248.690002</td>\n",
       "      <td>245.220001</td>\n",
       "      <td>245.550003</td>\n",
       "      <td>53197400</td>\n",
       "      <td>240.208448</td>\n",
       "      <td>237.920002</td>\n",
       "      <td>2.288446</td>\n",
       "      <td>0.363129</td>\n",
       "      <td>62.766179</td>\n",
       "      <td>103.163767</td>\n",
       "      <td>31.180457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-24 00:00:00-05:00</th>\n",
       "      <td>244.929993</td>\n",
       "      <td>248.860001</td>\n",
       "      <td>244.419998</td>\n",
       "      <td>247.100006</td>\n",
       "      <td>51326400</td>\n",
       "      <td>241.268688</td>\n",
       "      <td>238.600002</td>\n",
       "      <td>2.668686</td>\n",
       "      <td>0.824240</td>\n",
       "      <td>80.231290</td>\n",
       "      <td>90.587796</td>\n",
       "      <td>28.337470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-25 00:00:00-05:00</th>\n",
       "      <td>248.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>244.910004</td>\n",
       "      <td>247.039993</td>\n",
       "      <td>48013300</td>\n",
       "      <td>242.156581</td>\n",
       "      <td>239.225187</td>\n",
       "      <td>2.931394</td>\n",
       "      <td>1.245671</td>\n",
       "      <td>76.585168</td>\n",
       "      <td>83.906297</td>\n",
       "      <td>24.582475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-26 00:00:00-05:00</th>\n",
       "      <td>244.330002</td>\n",
       "      <td>244.979996</td>\n",
       "      <td>239.130005</td>\n",
       "      <td>240.360001</td>\n",
       "      <td>44433600</td>\n",
       "      <td>241.880184</td>\n",
       "      <td>239.309247</td>\n",
       "      <td>2.570937</td>\n",
       "      <td>1.510724</td>\n",
       "      <td>62.116289</td>\n",
       "      <td>19.244203</td>\n",
       "      <td>21.212065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-27 00:00:00-05:00</th>\n",
       "      <td>239.410004</td>\n",
       "      <td>242.460007</td>\n",
       "      <td>237.059998</td>\n",
       "      <td>237.300003</td>\n",
       "      <td>41078200</td>\n",
       "      <td>241.175541</td>\n",
       "      <td>239.160414</td>\n",
       "      <td>2.015127</td>\n",
       "      <td>1.611605</td>\n",
       "      <td>56.035173</td>\n",
       "      <td>-15.982410</td>\n",
       "      <td>18.992802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "2025-02-21 00:00:00-05:00  245.949997  248.690002  245.220001  245.550003   \n",
       "2025-02-24 00:00:00-05:00  244.929993  248.860001  244.419998  247.100006   \n",
       "2025-02-25 00:00:00-05:00  248.000000  250.000000  244.910004  247.039993   \n",
       "2025-02-26 00:00:00-05:00  244.330002  244.979996  239.130005  240.360001   \n",
       "2025-02-27 00:00:00-05:00  239.410004  242.460007  237.059998  237.300003   \n",
       "\n",
       "                             Volume      EMA_12      EMA_26      MACD  \\\n",
       "Date                                                                    \n",
       "2025-02-21 00:00:00-05:00  53197400  240.208448  237.920002  2.288446   \n",
       "2025-02-24 00:00:00-05:00  51326400  241.268688  238.600002  2.668686   \n",
       "2025-02-25 00:00:00-05:00  48013300  242.156581  239.225187  2.931394   \n",
       "2025-02-26 00:00:00-05:00  44433600  241.880184  239.309247  2.570937   \n",
       "2025-02-27 00:00:00-05:00  41078200  241.175541  239.160414  2.015127   \n",
       "\n",
       "                             Signal        RSI         CCI        ADX  \n",
       "Date                                                                   \n",
       "2025-02-21 00:00:00-05:00  0.363129  62.766179  103.163767  31.180457  \n",
       "2025-02-24 00:00:00-05:00  0.824240  80.231290   90.587796  28.337470  \n",
       "2025-02-25 00:00:00-05:00  1.245671  76.585168   83.906297  24.582475  \n",
       "2025-02-26 00:00:00-05:00  1.510724  62.116289   19.244203  21.212065  \n",
       "2025-02-27 00:00:00-05:00  1.611605  56.035173  -15.982410  18.992802  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03484219, 0.03398254, 0.03452298, 0.03425526, 0.2703879 ,\n",
       "       0.03184143, 0.03052919, 0.42180037, 0.40620287, 0.45542002,\n",
       "       0.59169241, 0.3071847 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalizing data\n",
    "data = data.values\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "data_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda_tmp\\ipykernel_1912\\1879639991.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  x = torch.tensor(xs).type(torch.float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0348, 0.0340, 0.0345, 0.0343, 0.2704, 0.0318, 0.0305, 0.4218, 0.4062,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0346, 0.0333, 0.0343, 0.0345, 0.2047, 0.0319, 0.0305, 0.4221, 0.4063,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0347, 0.0333, 0.0345, 0.0337, 0.1653, 0.0318, 0.0305, 0.4214, 0.4062,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0342, 0.0326, 0.0321, 0.0317, 0.3242, 0.0314, 0.0303, 0.4184, 0.4054,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0340, 0.0331, 0.0326, 0.0319, 0.4286, 0.0311, 0.0301, 0.4163, 0.4044,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0336, 0.0333, 0.0315, 0.0324, 0.5289, 0.0309, 0.0300, 0.4153, 0.4033,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0322, 0.0311, 0.0303, 0.0300, 0.4031, 0.0304, 0.0297, 0.4116, 0.4016,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0306, 0.0288, 0.0287, 0.0278, 0.4037, 0.0296, 0.0293, 0.4062, 0.3991,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0283, 0.0290, 0.0282, 0.0299, 0.2721, 0.0292, 0.0290, 0.4047, 0.3967,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0303, 0.0294, 0.0291, 0.0291, 0.2942, 0.0288, 0.0287, 0.4027, 0.3944,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0298, 0.0290, 0.0294, 0.0304, 0.1922, 0.0287, 0.0286, 0.4030, 0.3926,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0317, 0.0312, 0.0320, 0.0323, 0.2891, 0.0289, 0.0286, 0.4058, 0.3918,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0327, 0.0329, 0.0327, 0.0337, 0.3802, 0.0292, 0.0287, 0.4098, 0.3920,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0344, 0.0330, 0.0337, 0.0328, 0.2558, 0.0294, 0.0287, 0.4120, 0.3927,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0339, 0.0322, 0.0316, 0.0313, 0.4021, 0.0293, 0.0286, 0.4120, 0.3932,\n",
       "          0.4150, 0.5206, 0.3072],\n",
       "         [0.0328, 0.0317, 0.0328, 0.0325, 0.2040, 0.0294, 0.0286, 0.4136, 0.3940,\n",
       "          0.4469, 0.5714, 0.3072],\n",
       "         [0.0329, 0.0319, 0.0329, 0.0320, 0.1729, 0.0294, 0.0286, 0.4143, 0.3948,\n",
       "          0.4541, 0.5765, 0.3072],\n",
       "         [0.0323, 0.0307, 0.0299, 0.0289, 0.2931, 0.0289, 0.0283, 0.4112, 0.3947,\n",
       "          0.4270, 0.4279, 0.3072],\n",
       "         [0.0287, 0.0289, 0.0291, 0.0297, 0.2670, 0.0287, 0.0281, 0.4098, 0.3944,\n",
       "          0.4457, 0.4078, 0.3072],\n",
       "         [0.0304, 0.0288, 0.0294, 0.0288, 0.2157, 0.0283, 0.0278, 0.4077, 0.3936,\n",
       "          0.4102, 0.4058, 0.3072],\n",
       "         [0.0299, 0.0304, 0.0305, 0.0317, 0.2640, 0.0284, 0.0278, 0.4099, 0.3935,\n",
       "          0.5472, 0.5216, 0.3072],\n",
       "         [0.0319, 0.0304, 0.0308, 0.0299, 0.2320, 0.0283, 0.0277, 0.4095, 0.3933,\n",
       "          0.5557, 0.4802, 0.3072],\n",
       "         [0.0307, 0.0292, 0.0296, 0.0297, 0.2226, 0.0281, 0.0276, 0.4091, 0.3931,\n",
       "          0.4983, 0.4140, 0.3072],\n",
       "         [0.0309, 0.0296, 0.0306, 0.0307, 0.1689, 0.0281, 0.0275, 0.4101, 0.3931,\n",
       "          0.5484, 0.4644, 0.3072],\n",
       "         [0.0303, 0.0314, 0.0308, 0.0326, 0.2007, 0.0284, 0.0276, 0.4134, 0.3939,\n",
       "          0.5638, 0.5526, 0.3072],\n",
       "         [0.0333, 0.0320, 0.0323, 0.0314, 0.1867, 0.0285, 0.0276, 0.4146, 0.3948,\n",
       "          0.4767, 0.5749, 0.3072],\n",
       "         [0.0316, 0.0304, 0.0314, 0.0310, 0.2015, 0.0285, 0.0275, 0.4151, 0.3956,\n",
       "          0.4250, 0.5099, 0.3072],\n",
       "         [0.0316, 0.0305, 0.0311, 0.0319, 0.1706, 0.0286, 0.0276, 0.4167, 0.3966,\n",
       "          0.4778, 0.5511, 0.3072],\n",
       "         [0.0317, 0.0311, 0.0317, 0.0324, 0.2198, 0.0288, 0.0277, 0.4186, 0.3978,\n",
       "          0.5383, 0.6079, 0.2795],\n",
       "         [0.0340, 0.0324, 0.0329, 0.0322, 0.1954, 0.0290, 0.0277, 0.4198, 0.3990,\n",
       "          0.4925, 0.6847, 0.2672]]),\n",
       " tensor([0.0327, 0.0312, 0.0323, 0.0316, 0.1261, 0.0290, 0.0277, 0.4202, 0.4001,\n",
       "         0.4916, 0.6115, 0.2574]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing dataset for LSTM\n",
    "\n",
    "sequence_len = 30   #considering 30 days window\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for i in range(len(data_scaled) - sequence_len):\n",
    "    xs.append(data_scaled[i:i+sequence_len])\n",
    "    ys.append(data_scaled[i+sequence_len])\n",
    "\n",
    "x = torch.tensor(xs).type(torch.float32)\n",
    "y = torch.tensor(ys).type(torch.float32)\n",
    "x[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2485, 30, 12]), torch.Size([2485, 12]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1988\n",
      "torch.Size([1988, 30, 12]) torch.Size([497, 30, 12]) torch.Size([1988, 12]) torch.Size([497, 12])\n"
     ]
    }
   ],
   "source": [
    "# dividing data into train and test set\n",
    "split_ratio = 0.8\n",
    "split_size = int(len(x) * split_ratio)\n",
    "print(split_size)\n",
    "\n",
    "X_train = x[:split_size]\n",
    "X_test = x[split_size:]\n",
    "y_train = y[:split_size]\n",
    "y_test = y[split_size:]\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0348, 0.0340, 0.0345, 0.0343, 0.2704, 0.0318, 0.0305, 0.4218, 0.4062,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0346, 0.0333, 0.0343, 0.0345, 0.2047, 0.0319, 0.0305, 0.4221, 0.4063,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0347, 0.0333, 0.0345, 0.0337, 0.1653, 0.0318, 0.0305, 0.4214, 0.4062,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0342, 0.0326, 0.0321, 0.0317, 0.3242, 0.0314, 0.0303, 0.4184, 0.4054,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0340, 0.0331, 0.0326, 0.0319, 0.4286, 0.0311, 0.0301, 0.4163, 0.4044,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0336, 0.0333, 0.0315, 0.0324, 0.5289, 0.0309, 0.0300, 0.4153, 0.4033,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0322, 0.0311, 0.0303, 0.0300, 0.4031, 0.0304, 0.0297, 0.4116, 0.4016,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0306, 0.0288, 0.0287, 0.0278, 0.4037, 0.0296, 0.0293, 0.4062, 0.3991,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0283, 0.0290, 0.0282, 0.0299, 0.2721, 0.0292, 0.0290, 0.4047, 0.3967,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0303, 0.0294, 0.0291, 0.0291, 0.2942, 0.0288, 0.0287, 0.4027, 0.3944,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0298, 0.0290, 0.0294, 0.0304, 0.1922, 0.0287, 0.0286, 0.4030, 0.3926,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0317, 0.0312, 0.0320, 0.0323, 0.2891, 0.0289, 0.0286, 0.4058, 0.3918,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0327, 0.0329, 0.0327, 0.0337, 0.3802, 0.0292, 0.0287, 0.4098, 0.3920,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0344, 0.0330, 0.0337, 0.0328, 0.2558, 0.0294, 0.0287, 0.4120, 0.3927,\n",
       "          0.4554, 0.5917, 0.3072],\n",
       "         [0.0339, 0.0322, 0.0316, 0.0313, 0.4021, 0.0293, 0.0286, 0.4120, 0.3932,\n",
       "          0.4150, 0.5206, 0.3072],\n",
       "         [0.0328, 0.0317, 0.0328, 0.0325, 0.2040, 0.0294, 0.0286, 0.4136, 0.3940,\n",
       "          0.4469, 0.5714, 0.3072],\n",
       "         [0.0329, 0.0319, 0.0329, 0.0320, 0.1729, 0.0294, 0.0286, 0.4143, 0.3948,\n",
       "          0.4541, 0.5765, 0.3072],\n",
       "         [0.0323, 0.0307, 0.0299, 0.0289, 0.2931, 0.0289, 0.0283, 0.4112, 0.3947,\n",
       "          0.4270, 0.4279, 0.3072],\n",
       "         [0.0287, 0.0289, 0.0291, 0.0297, 0.2670, 0.0287, 0.0281, 0.4098, 0.3944,\n",
       "          0.4457, 0.4078, 0.3072],\n",
       "         [0.0304, 0.0288, 0.0294, 0.0288, 0.2157, 0.0283, 0.0278, 0.4077, 0.3936,\n",
       "          0.4102, 0.4058, 0.3072],\n",
       "         [0.0299, 0.0304, 0.0305, 0.0317, 0.2640, 0.0284, 0.0278, 0.4099, 0.3935,\n",
       "          0.5472, 0.5216, 0.3072],\n",
       "         [0.0319, 0.0304, 0.0308, 0.0299, 0.2320, 0.0283, 0.0277, 0.4095, 0.3933,\n",
       "          0.5557, 0.4802, 0.3072],\n",
       "         [0.0307, 0.0292, 0.0296, 0.0297, 0.2226, 0.0281, 0.0276, 0.4091, 0.3931,\n",
       "          0.4983, 0.4140, 0.3072],\n",
       "         [0.0309, 0.0296, 0.0306, 0.0307, 0.1689, 0.0281, 0.0275, 0.4101, 0.3931,\n",
       "          0.5484, 0.4644, 0.3072],\n",
       "         [0.0303, 0.0314, 0.0308, 0.0326, 0.2007, 0.0284, 0.0276, 0.4134, 0.3939,\n",
       "          0.5638, 0.5526, 0.3072],\n",
       "         [0.0333, 0.0320, 0.0323, 0.0314, 0.1867, 0.0285, 0.0276, 0.4146, 0.3948,\n",
       "          0.4767, 0.5749, 0.3072],\n",
       "         [0.0316, 0.0304, 0.0314, 0.0310, 0.2015, 0.0285, 0.0275, 0.4151, 0.3956,\n",
       "          0.4250, 0.5099, 0.3072],\n",
       "         [0.0316, 0.0305, 0.0311, 0.0319, 0.1706, 0.0286, 0.0276, 0.4167, 0.3966,\n",
       "          0.4778, 0.5511, 0.3072],\n",
       "         [0.0317, 0.0311, 0.0317, 0.0324, 0.2198, 0.0288, 0.0277, 0.4186, 0.3978,\n",
       "          0.5383, 0.6079, 0.2795],\n",
       "         [0.0340, 0.0324, 0.0329, 0.0322, 0.1954, 0.0290, 0.0277, 0.4198, 0.3990,\n",
       "          0.4925, 0.6847, 0.2672]]),\n",
       " tensor([0.0327, 0.0312, 0.0323, 0.0316, 0.1261, 0.0290, 0.0277, 0.4202, 0.4001,\n",
       "         0.4916, 0.6115, 0.2574]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### build LSTM model\n",
    "\n",
    "class LSTMv0(nn.Module):\n",
    "    def __init__(self, input_features, hidden_features, num_layers, output_features):\n",
    "        super().__init__()\n",
    "        self.hidden_features = hidden_features\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_features, hidden_features, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_features, output_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_features)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_features)\n",
    "\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out)\n",
    "        return out[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "INPUT_FEATURES = len(X_train[0, 0, :])\n",
    "HIDDEN_FEATURES = 30\n",
    "NUM_LAYERS = 3\n",
    "OUTPUT_FEATURES = len(y_train[0, :])\n",
    "\n",
    "model_0 = LSTMv0(INPUT_FEATURES, HIDDEN_FEATURES, NUM_LAYERS, OUTPUT_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMv0(\n",
       "  (lstm): LSTM(12, 30, num_layers=3, batch_first=True)\n",
       "  (fc): Linear(in_features=30, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 0.1438 | Test Loss: 0.3873\n",
      "Epoch: 20 | Loss: 0.1343 | Test Loss: 0.3722\n",
      "Epoch: 40 | Loss: 0.1255 | Test Loss: 0.3583\n",
      "Epoch: 60 | Loss: 0.1176 | Test Loss: 0.3453\n",
      "Epoch: 80 | Loss: 0.1102 | Test Loss: 0.3332\n",
      "Epoch: 100 | Loss: 0.1036 | Test Loss: 0.3219\n",
      "Epoch: 120 | Loss: 0.0974 | Test Loss: 0.3113\n",
      "Epoch: 140 | Loss: 0.0918 | Test Loss: 0.3014\n",
      "Epoch: 160 | Loss: 0.0867 | Test Loss: 0.2922\n",
      "Epoch: 180 | Loss: 0.0819 | Test Loss: 0.2836\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "epochs = 200\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # train mode\n",
    "    model_0.train()\n",
    "\n",
    "    # forward pass\n",
    "    y_pred = model_0(X_train)\n",
    "\n",
    "    # calulate loss\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    # optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # backward\n",
    "    loss.backward()\n",
    "\n",
    "    # step optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_pred = model_0(X_test)\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "    # print\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.4f} | Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1817,  0.0841,  0.0656,  0.0115,  0.0249,  0.1987, -0.0058,  0.1386,\n",
       "          0.2414,  0.3063,  0.2020,  0.0855],\n",
       "        [ 0.1817,  0.0841,  0.0656,  0.0114,  0.0248,  0.1989, -0.0059,  0.1386,\n",
       "          0.2412,  0.3063,  0.2020,  0.0854],\n",
       "        [ 0.1817,  0.0840,  0.0657,  0.0113,  0.0247,  0.1991, -0.0059,  0.1386,\n",
       "          0.2412,  0.3063,  0.2020,  0.0853],\n",
       "        [ 0.1818,  0.0840,  0.0657,  0.0112,  0.0247,  0.1992, -0.0060,  0.1386,\n",
       "          0.2412,  0.3062,  0.2020,  0.0853],\n",
       "        [ 0.1818,  0.0840,  0.0656,  0.0112,  0.0247,  0.1993, -0.0060,  0.1386,\n",
       "          0.2412,  0.3063,  0.2020,  0.0853]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate model with test values\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    eval_pred = model_0(X_test)\n",
    "eval_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1838,  0.0838,  0.0634,  0.0108,  0.0244,  0.2005, -0.0067,  0.1374,\n",
       "          0.2425,  0.3060,  0.2017,  0.0864],\n",
       "        [ 0.1839,  0.0837,  0.0633,  0.0108,  0.0245,  0.2004, -0.0067,  0.1373,\n",
       "          0.2428,  0.3058,  0.2015,  0.0864],\n",
       "        [ 0.1839,  0.0836,  0.0634,  0.0107,  0.0245,  0.2004, -0.0067,  0.1372,\n",
       "          0.2430,  0.3055,  0.2014,  0.0864],\n",
       "        [ 0.1840,  0.0835,  0.0635,  0.0106,  0.0245,  0.2004, -0.0066,  0.1371,\n",
       "          0.2432,  0.3053,  0.2012,  0.0864],\n",
       "        [ 0.1840,  0.0834,  0.0635,  0.0105,  0.0246,  0.2004, -0.0066,  0.1370,\n",
       "          0.2434,  0.3051,  0.2011,  0.0865]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_pred[-5: ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Start from scratch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plan**\n",
    "1. Make LSTM function that can be used to fit different dataframes, and Train in seperately\n",
    "2. Make Stock Trading Env\n",
    "3. Use Stable_Baselines3 to import PPO model, and Trian it with LSTM(that are trained before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Make a function that can take data and break-down it into different dataframes (or inputs)\n",
    "\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# def data_fragmenter(df: pd.DataFrame):\n",
    "#     scaler = MinMaxScaler()\n",
    "#     df_fundamental = df[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
    "#     df_mavg = df[[\"EMA_12\", \"EMA_26\"]]\n",
    "#     df_mi = df[[\"MACD\", \"Signal\", \"RSI\", \"CCI\"]]\n",
    "#     df_adx = df[[\"ADX\"]]\n",
    "\n",
    "#     # normalize\n",
    "#     df_fundamental = scaler.fit_transform(df_fundamental)\n",
    "#     df_mavg = scaler.fit_transform(df_mavg)\n",
    "#     df_mi = scaler.fit_transform(df_mi)\n",
    "#     df_adx = scaler.fit_transform(df_adx)\n",
    "\n",
    "#     return df_fundamental, df_mavg, df_mi, df_adx\n",
    "\n",
    "# df = pd.read_csv(\"./stocks_data/AAPL_data.csv\")\n",
    "# fundamental, mavg, mi, adx = data_fragmenter(df=df)\n",
    "# fundamental[:5], mavg[:5], mi[:5], adx[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Break Down data into columns or dataframes\n",
    "1. Open, High, Low, Close, Volume -> Fundamental Data\n",
    "2. EMA_12, EMA_26 -> Moving Avgs\n",
    "3. MACD, Signal, RSI, CCI -> Momentum Indicators\n",
    "4. ADX -> Trend Strength (ADX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def data_sequencer(data: torch.Tensor, sequence_len: int, device=\"cpu\"):\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for i in range(len(data) - sequence_len):\n",
    "        xs.append(data[i: i+sequence_len])\n",
    "        ys.append(data[i+sequence_len])\n",
    "\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "\n",
    "    xs = torch.tensor(xs, dtype=torch.float32, device=device)\n",
    "    ys = torch.tensor(ys, dtype=torch.float32, device=device)\n",
    "\n",
    "    return xs, ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def data_fragmenter(df: pd.DataFrame, device=\"cpu\"):\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    df_fundamental = df[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
    "    df_mavg = df[[\"EMA_12\", \"EMA_26\"]]\n",
    "    df_mi = df[[\"MACD\", \"Signal\", \"RSI\", \"CCI\"]]\n",
    "    df_adx = df[[\"ADX\"]]\n",
    "\n",
    "    # normalize\n",
    "    df_fundamental = scaler.fit_transform(df_fundamental)\n",
    "    df_mavg = scaler.fit_transform(df_mavg)\n",
    "    df_mi = scaler.fit_transform(df_mi)\n",
    "    df_adx = scaler.fit_transform(df_adx)\n",
    "\n",
    "    fundamental_x, fundamental_y = data_sequencer(df_fundamental, 30, device=device)\n",
    "    mavg_x, mavg_y = data_sequencer(df_mavg, 30, device=device)\n",
    "    mi_x, mi_y = data_sequencer(df_mi, 30, device=device)\n",
    "    adx_x, adx_y = data_sequencer(df_adx, 30, device=device)\n",
    "\n",
    "    return fundamental_x, fundamental_y, mavg_x, mavg_y, mi_x, mi_y, adx_x, adx_y\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./stocks_data/AAPL_data.csv\")\n",
    "fundamental_x, fundamental_y, mavg_x, mavg_y, mi_x, mi_y, adx_x, adx_y = data_fragmenter(df=df, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make LSTM that can adapt to shape of data\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class LSTMv1(nn.Module):\n",
    "    def __init__(self, input_features, hidden_features, num_layers, output_features, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.hidden_features = hidden_features\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "\n",
    "        self.lstm = nn.LSTM(input_features, hidden_features, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_features, output_features)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_features, device=self.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_features, device=self.device)\n",
    "\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out)\n",
    "        return out[:, -1, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_FEATURES = len(X_train[0, 0, :])\n",
    "# HIDDEN_FEATURES = 30\n",
    "# NUM_LAYERS = 3\n",
    "# OUTPUT_FEATURES = len(y_train[0, :])\n",
    "\n",
    "model_fundamental = LSTMv1(len(fundamental_x[0, 0, :]), hidden_features=30, num_layers=3, output_features=len(fundamental_y[0, :]), device=device)\n",
    "model_mavg = LSTMv1(len(mavg_x[0, 0, :]), hidden_features=30, num_layers=3, output_features=len(mavg_y[0, :]), device=device)\n",
    "model_mi = LSTMv1(len(mi_x[0, 0, :]), hidden_features=30, num_layers=3, output_features=len(mi_y[0, :]), device=device)\n",
    "model_adx = LSTMv1(len(adx_x[0, 0, :]), hidden_features=30, num_layers=3, output_features=len(adx_y[0, :]), device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LSTMv1(\n",
       "   (lstm): LSTM(5, 30, num_layers=3, batch_first=True)\n",
       "   (fc): Linear(in_features=30, out_features=5, bias=True)\n",
       " ),\n",
       " LSTMv1(\n",
       "   (lstm): LSTM(2, 30, num_layers=3, batch_first=True)\n",
       "   (fc): Linear(in_features=30, out_features=2, bias=True)\n",
       " ),\n",
       " LSTMv1(\n",
       "   (lstm): LSTM(4, 30, num_layers=3, batch_first=True)\n",
       "   (fc): Linear(in_features=30, out_features=4, bias=True)\n",
       " ),\n",
       " LSTMv1(\n",
       "   (lstm): LSTM(1, 30, num_layers=3, batch_first=True)\n",
       "   (fc): Linear(in_features=30, out_features=1, bias=True)\n",
       " ))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fundamental, model_mavg, model_mi, model_adx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamental_loss_fn = nn.MSELoss().to(device)\n",
    "mavg_loss_fn = nn.MSELoss().to(device)\n",
    "mi_loss_fn = nn.MSELoss().to(device)\n",
    "adx_loss_fn = nn.MSELoss().to(device)\n",
    "\n",
    "optimizer_fundamental = torch.optim.Adam(params=model_fundamental.parameters(), lr=0.001)\n",
    "optimizer_mavg = torch.optim.Adam(params=model_mavg.parameters(), lr=0.001)\n",
    "optimizer_mi = torch.optim.Adam(params=model_mi.parameters(), lr=0.001)\n",
    "optimizer_adx = torch.optim.Adam(params=model_adx.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MRK_data.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Alternate training\n",
    "import random\n",
    "import os\n",
    "file = random.choice(os.listdir(\"./stocks_data\"))\n",
    "file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Pick a random file\n",
    "2. read csv data as df\n",
    "3. process df with data_fragmenter()\n",
    "4. provide inputs to model\n",
    "5. train certain epochs(10) with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "import random, os, fnmatch\n",
    "import pandas as pd\n",
    "import torch\n",
    "epochs = 200\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # pick a random file from dir\n",
    "    file = random.choice(os.listdir(\"./stocks_data\"))\n",
    "    if file.endswith(\".csv\"):\n",
    "        # read csv file\n",
    "        df = pd.read_csv(file)\n",
    "        fundamental_x, fundamental_y, mavg_x, mavg_y, mi_x, mi_y, adx_x, adx_y = data_fragmenter(df=df, device=device)\n",
    "\n",
    "        ## training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
