{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fq6ELSWbU44i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsyyT-zhU44k",
        "outputId": "41ca4619-f263-439a-9154-2dc7d30b729c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>EMA_12</th>\n",
              "      <th>EMA_26</th>\n",
              "      <th>MACD</th>\n",
              "      <th>Signal</th>\n",
              "      <th>RSI</th>\n",
              "      <th>CCI</th>\n",
              "      <th>ADX</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-03-02 00:00:00-05:00</td>\n",
              "      <td>28.865108</td>\n",
              "      <td>29.095135</td>\n",
              "      <td>28.652947</td>\n",
              "      <td>28.829374</td>\n",
              "      <td>192386800</td>\n",
              "      <td>28.829374</td>\n",
              "      <td>28.829374</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>45.526105</td>\n",
              "      <td>56.240216</td>\n",
              "      <td>28.673114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-03-03 00:00:00-05:00</td>\n",
              "      <td>28.800338</td>\n",
              "      <td>28.925401</td>\n",
              "      <td>28.606040</td>\n",
              "      <td>28.889668</td>\n",
              "      <td>151265200</td>\n",
              "      <td>28.838650</td>\n",
              "      <td>28.833840</td>\n",
              "      <td>0.004810</td>\n",
              "      <td>0.000962</td>\n",
              "      <td>45.526105</td>\n",
              "      <td>56.240216</td>\n",
              "      <td>28.673114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-03-04 00:00:00-05:00</td>\n",
              "      <td>28.831606</td>\n",
              "      <td>28.934334</td>\n",
              "      <td>28.657410</td>\n",
              "      <td>28.706539</td>\n",
              "      <td>126665200</td>\n",
              "      <td>28.818325</td>\n",
              "      <td>28.824411</td>\n",
              "      <td>-0.006085</td>\n",
              "      <td>-0.000448</td>\n",
              "      <td>45.526105</td>\n",
              "      <td>56.240216</td>\n",
              "      <td>28.673114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-03-05 00:00:00-05:00</td>\n",
              "      <td>28.715477</td>\n",
              "      <td>28.753442</td>\n",
              "      <td>28.085693</td>\n",
              "      <td>28.230856</td>\n",
              "      <td>226068400</td>\n",
              "      <td>28.727945</td>\n",
              "      <td>28.780444</td>\n",
              "      <td>-0.052498</td>\n",
              "      <td>-0.010858</td>\n",
              "      <td>45.526105</td>\n",
              "      <td>56.240216</td>\n",
              "      <td>28.673114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-03-06 00:00:00-05:00</td>\n",
              "      <td>28.675274</td>\n",
              "      <td>28.891902</td>\n",
              "      <td>28.197354</td>\n",
              "      <td>28.273285</td>\n",
              "      <td>291368400</td>\n",
              "      <td>28.657998</td>\n",
              "      <td>28.742876</td>\n",
              "      <td>-0.084879</td>\n",
              "      <td>-0.025662</td>\n",
              "      <td>45.526105</td>\n",
              "      <td>56.240216</td>\n",
              "      <td>28.673114</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Date       Open       High        Low      Close  \\\n",
              "0  2015-03-02 00:00:00-05:00  28.865108  29.095135  28.652947  28.829374   \n",
              "1  2015-03-03 00:00:00-05:00  28.800338  28.925401  28.606040  28.889668   \n",
              "2  2015-03-04 00:00:00-05:00  28.831606  28.934334  28.657410  28.706539   \n",
              "3  2015-03-05 00:00:00-05:00  28.715477  28.753442  28.085693  28.230856   \n",
              "4  2015-03-06 00:00:00-05:00  28.675274  28.891902  28.197354  28.273285   \n",
              "\n",
              "      Volume     EMA_12     EMA_26      MACD    Signal        RSI        CCI  \\\n",
              "0  192386800  28.829374  28.829374  0.000000  0.000000  45.526105  56.240216   \n",
              "1  151265200  28.838650  28.833840  0.004810  0.000962  45.526105  56.240216   \n",
              "2  126665200  28.818325  28.824411 -0.006085 -0.000448  45.526105  56.240216   \n",
              "3  226068400  28.727945  28.780444 -0.052498 -0.010858  45.526105  56.240216   \n",
              "4  291368400  28.657998  28.742876 -0.084879 -0.025662  45.526105  56.240216   \n",
              "\n",
              "         ADX  \n",
              "0  28.673114  \n",
              "1  28.673114  \n",
              "2  28.673114  \n",
              "3  28.673114  \n",
              "4  28.673114  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"./stocks_data/AAPL_data.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nq_D-i70U44n",
        "outputId": "57f34236-c429-4b42-ea5a-dde7c4bb1118"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2515, (2515, 13))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data), data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFUtKeWJU44n",
        "outputId": "f9704bdb-d854-4500-c8d0-ba9227b8b37e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'EMA_12', 'EMA_26',\n",
              "       'MACD', 'Signal', 'RSI', 'CCI', 'ADX'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJl7epEyU44o"
      },
      "outputs": [],
      "source": [
        "data = data.set_index(\"Date\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BTVZcL8U44o",
        "outputId": "33e69c3b-b9e8-49ce-f9d0-43255c070462"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>EMA_12</th>\n",
              "      <th>EMA_26</th>\n",
              "      <th>MACD</th>\n",
              "      <th>Signal</th>\n",
              "      <th>RSI</th>\n",
              "      <th>CCI</th>\n",
              "      <th>ADX</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2025-02-21 00:00:00-05:00</th>\n",
              "      <td>245.949997</td>\n",
              "      <td>248.690002</td>\n",
              "      <td>245.220001</td>\n",
              "      <td>245.550003</td>\n",
              "      <td>53197400</td>\n",
              "      <td>240.208448</td>\n",
              "      <td>237.920002</td>\n",
              "      <td>2.288446</td>\n",
              "      <td>0.363129</td>\n",
              "      <td>62.766179</td>\n",
              "      <td>103.163767</td>\n",
              "      <td>31.180457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-02-24 00:00:00-05:00</th>\n",
              "      <td>244.929993</td>\n",
              "      <td>248.860001</td>\n",
              "      <td>244.419998</td>\n",
              "      <td>247.100006</td>\n",
              "      <td>51326400</td>\n",
              "      <td>241.268688</td>\n",
              "      <td>238.600002</td>\n",
              "      <td>2.668686</td>\n",
              "      <td>0.824240</td>\n",
              "      <td>80.231290</td>\n",
              "      <td>90.587796</td>\n",
              "      <td>28.337470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-02-25 00:00:00-05:00</th>\n",
              "      <td>248.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>244.910004</td>\n",
              "      <td>247.039993</td>\n",
              "      <td>48013300</td>\n",
              "      <td>242.156581</td>\n",
              "      <td>239.225187</td>\n",
              "      <td>2.931394</td>\n",
              "      <td>1.245671</td>\n",
              "      <td>76.585168</td>\n",
              "      <td>83.906297</td>\n",
              "      <td>24.582475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-02-26 00:00:00-05:00</th>\n",
              "      <td>244.330002</td>\n",
              "      <td>244.979996</td>\n",
              "      <td>239.130005</td>\n",
              "      <td>240.360001</td>\n",
              "      <td>44433600</td>\n",
              "      <td>241.880184</td>\n",
              "      <td>239.309247</td>\n",
              "      <td>2.570937</td>\n",
              "      <td>1.510724</td>\n",
              "      <td>62.116289</td>\n",
              "      <td>19.244203</td>\n",
              "      <td>21.212065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-02-27 00:00:00-05:00</th>\n",
              "      <td>239.410004</td>\n",
              "      <td>242.460007</td>\n",
              "      <td>237.059998</td>\n",
              "      <td>237.300003</td>\n",
              "      <td>41078200</td>\n",
              "      <td>241.175541</td>\n",
              "      <td>239.160414</td>\n",
              "      <td>2.015127</td>\n",
              "      <td>1.611605</td>\n",
              "      <td>56.035173</td>\n",
              "      <td>-15.982410</td>\n",
              "      <td>18.992802</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 Open        High         Low       Close  \\\n",
              "Date                                                                        \n",
              "2025-02-21 00:00:00-05:00  245.949997  248.690002  245.220001  245.550003   \n",
              "2025-02-24 00:00:00-05:00  244.929993  248.860001  244.419998  247.100006   \n",
              "2025-02-25 00:00:00-05:00  248.000000  250.000000  244.910004  247.039993   \n",
              "2025-02-26 00:00:00-05:00  244.330002  244.979996  239.130005  240.360001   \n",
              "2025-02-27 00:00:00-05:00  239.410004  242.460007  237.059998  237.300003   \n",
              "\n",
              "                             Volume      EMA_12      EMA_26      MACD  \\\n",
              "Date                                                                    \n",
              "2025-02-21 00:00:00-05:00  53197400  240.208448  237.920002  2.288446   \n",
              "2025-02-24 00:00:00-05:00  51326400  241.268688  238.600002  2.668686   \n",
              "2025-02-25 00:00:00-05:00  48013300  242.156581  239.225187  2.931394   \n",
              "2025-02-26 00:00:00-05:00  44433600  241.880184  239.309247  2.570937   \n",
              "2025-02-27 00:00:00-05:00  41078200  241.175541  239.160414  2.015127   \n",
              "\n",
              "                             Signal        RSI         CCI        ADX  \n",
              "Date                                                                   \n",
              "2025-02-21 00:00:00-05:00  0.363129  62.766179  103.163767  31.180457  \n",
              "2025-02-24 00:00:00-05:00  0.824240  80.231290   90.587796  28.337470  \n",
              "2025-02-25 00:00:00-05:00  1.245671  76.585168   83.906297  24.582475  \n",
              "2025-02-26 00:00:00-05:00  1.510724  62.116289   19.244203  21.212065  \n",
              "2025-02-27 00:00:00-05:00  1.611605  56.035173  -15.982410  18.992802  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvB09lelU44p",
        "outputId": "98463854-cb4f-48f0-da4b-97e558995ada"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.03484219, 0.03398254, 0.03452298, 0.03425526, 0.2703879 ,\n",
              "       0.03184143, 0.03052919, 0.42180037, 0.40620287, 0.45542002,\n",
              "       0.59169241, 0.3071847 ])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# normalizing data\n",
        "data = data.values\n",
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "data_scaled[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0AaAVZoU44p",
        "outputId": "c70befff-9878-48a8-95d4-6df2fa727c7e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\conda_tmp\\ipykernel_1912\\1879639991.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
            "  x = torch.tensor(xs).type(torch.float32)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor([[0.0348, 0.0340, 0.0345, 0.0343, 0.2704, 0.0318, 0.0305, 0.4218, 0.4062,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0346, 0.0333, 0.0343, 0.0345, 0.2047, 0.0319, 0.0305, 0.4221, 0.4063,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0347, 0.0333, 0.0345, 0.0337, 0.1653, 0.0318, 0.0305, 0.4214, 0.4062,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0342, 0.0326, 0.0321, 0.0317, 0.3242, 0.0314, 0.0303, 0.4184, 0.4054,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0340, 0.0331, 0.0326, 0.0319, 0.4286, 0.0311, 0.0301, 0.4163, 0.4044,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0336, 0.0333, 0.0315, 0.0324, 0.5289, 0.0309, 0.0300, 0.4153, 0.4033,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0322, 0.0311, 0.0303, 0.0300, 0.4031, 0.0304, 0.0297, 0.4116, 0.4016,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0306, 0.0288, 0.0287, 0.0278, 0.4037, 0.0296, 0.0293, 0.4062, 0.3991,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0283, 0.0290, 0.0282, 0.0299, 0.2721, 0.0292, 0.0290, 0.4047, 0.3967,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0303, 0.0294, 0.0291, 0.0291, 0.2942, 0.0288, 0.0287, 0.4027, 0.3944,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0298, 0.0290, 0.0294, 0.0304, 0.1922, 0.0287, 0.0286, 0.4030, 0.3926,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0317, 0.0312, 0.0320, 0.0323, 0.2891, 0.0289, 0.0286, 0.4058, 0.3918,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0327, 0.0329, 0.0327, 0.0337, 0.3802, 0.0292, 0.0287, 0.4098, 0.3920,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0344, 0.0330, 0.0337, 0.0328, 0.2558, 0.0294, 0.0287, 0.4120, 0.3927,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0339, 0.0322, 0.0316, 0.0313, 0.4021, 0.0293, 0.0286, 0.4120, 0.3932,\n",
              "          0.4150, 0.5206, 0.3072],\n",
              "         [0.0328, 0.0317, 0.0328, 0.0325, 0.2040, 0.0294, 0.0286, 0.4136, 0.3940,\n",
              "          0.4469, 0.5714, 0.3072],\n",
              "         [0.0329, 0.0319, 0.0329, 0.0320, 0.1729, 0.0294, 0.0286, 0.4143, 0.3948,\n",
              "          0.4541, 0.5765, 0.3072],\n",
              "         [0.0323, 0.0307, 0.0299, 0.0289, 0.2931, 0.0289, 0.0283, 0.4112, 0.3947,\n",
              "          0.4270, 0.4279, 0.3072],\n",
              "         [0.0287, 0.0289, 0.0291, 0.0297, 0.2670, 0.0287, 0.0281, 0.4098, 0.3944,\n",
              "          0.4457, 0.4078, 0.3072],\n",
              "         [0.0304, 0.0288, 0.0294, 0.0288, 0.2157, 0.0283, 0.0278, 0.4077, 0.3936,\n",
              "          0.4102, 0.4058, 0.3072],\n",
              "         [0.0299, 0.0304, 0.0305, 0.0317, 0.2640, 0.0284, 0.0278, 0.4099, 0.3935,\n",
              "          0.5472, 0.5216, 0.3072],\n",
              "         [0.0319, 0.0304, 0.0308, 0.0299, 0.2320, 0.0283, 0.0277, 0.4095, 0.3933,\n",
              "          0.5557, 0.4802, 0.3072],\n",
              "         [0.0307, 0.0292, 0.0296, 0.0297, 0.2226, 0.0281, 0.0276, 0.4091, 0.3931,\n",
              "          0.4983, 0.4140, 0.3072],\n",
              "         [0.0309, 0.0296, 0.0306, 0.0307, 0.1689, 0.0281, 0.0275, 0.4101, 0.3931,\n",
              "          0.5484, 0.4644, 0.3072],\n",
              "         [0.0303, 0.0314, 0.0308, 0.0326, 0.2007, 0.0284, 0.0276, 0.4134, 0.3939,\n",
              "          0.5638, 0.5526, 0.3072],\n",
              "         [0.0333, 0.0320, 0.0323, 0.0314, 0.1867, 0.0285, 0.0276, 0.4146, 0.3948,\n",
              "          0.4767, 0.5749, 0.3072],\n",
              "         [0.0316, 0.0304, 0.0314, 0.0310, 0.2015, 0.0285, 0.0275, 0.4151, 0.3956,\n",
              "          0.4250, 0.5099, 0.3072],\n",
              "         [0.0316, 0.0305, 0.0311, 0.0319, 0.1706, 0.0286, 0.0276, 0.4167, 0.3966,\n",
              "          0.4778, 0.5511, 0.3072],\n",
              "         [0.0317, 0.0311, 0.0317, 0.0324, 0.2198, 0.0288, 0.0277, 0.4186, 0.3978,\n",
              "          0.5383, 0.6079, 0.2795],\n",
              "         [0.0340, 0.0324, 0.0329, 0.0322, 0.1954, 0.0290, 0.0277, 0.4198, 0.3990,\n",
              "          0.4925, 0.6847, 0.2672]]),\n",
              " tensor([0.0327, 0.0312, 0.0323, 0.0316, 0.1261, 0.0290, 0.0277, 0.4202, 0.4001,\n",
              "         0.4916, 0.6115, 0.2574]))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# preparing dataset for LSTM\n",
        "\n",
        "sequence_len = 30   #considering 30 days window\n",
        "xs = []\n",
        "ys = []\n",
        "\n",
        "for i in range(len(data_scaled) - sequence_len):\n",
        "    xs.append(data_scaled[i:i+sequence_len])\n",
        "    ys.append(data_scaled[i+sequence_len])\n",
        "\n",
        "x = torch.tensor(xs).type(torch.float32)\n",
        "y = torch.tensor(ys).type(torch.float32)\n",
        "x[0], y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lvfBcLvU44q",
        "outputId": "3885a2a8-e26b-4d71-e78c-305ec4a542e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([2485, 30, 12]), torch.Size([2485, 12]))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZBcnzjUU44r",
        "outputId": "39cd1fae-7dd8-43c7-ef17-09ad6b8bb47d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1988\n",
            "torch.Size([1988, 30, 12]) torch.Size([497, 30, 12]) torch.Size([1988, 12]) torch.Size([497, 12])\n"
          ]
        }
      ],
      "source": [
        "# dividing data into train and test set\n",
        "split_ratio = 0.8\n",
        "split_size = int(len(x) * split_ratio)\n",
        "print(split_size)\n",
        "\n",
        "X_train = x[:split_size]\n",
        "X_test = x[split_size:]\n",
        "y_train = y[:split_size]\n",
        "y_test = y[split_size:]\n",
        "\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqLg8pBHU44s",
        "outputId": "39a8e675-f145-454e-b600-2d075fa21697"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.0348, 0.0340, 0.0345, 0.0343, 0.2704, 0.0318, 0.0305, 0.4218, 0.4062,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0346, 0.0333, 0.0343, 0.0345, 0.2047, 0.0319, 0.0305, 0.4221, 0.4063,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0347, 0.0333, 0.0345, 0.0337, 0.1653, 0.0318, 0.0305, 0.4214, 0.4062,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0342, 0.0326, 0.0321, 0.0317, 0.3242, 0.0314, 0.0303, 0.4184, 0.4054,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0340, 0.0331, 0.0326, 0.0319, 0.4286, 0.0311, 0.0301, 0.4163, 0.4044,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0336, 0.0333, 0.0315, 0.0324, 0.5289, 0.0309, 0.0300, 0.4153, 0.4033,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0322, 0.0311, 0.0303, 0.0300, 0.4031, 0.0304, 0.0297, 0.4116, 0.4016,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0306, 0.0288, 0.0287, 0.0278, 0.4037, 0.0296, 0.0293, 0.4062, 0.3991,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0283, 0.0290, 0.0282, 0.0299, 0.2721, 0.0292, 0.0290, 0.4047, 0.3967,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0303, 0.0294, 0.0291, 0.0291, 0.2942, 0.0288, 0.0287, 0.4027, 0.3944,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0298, 0.0290, 0.0294, 0.0304, 0.1922, 0.0287, 0.0286, 0.4030, 0.3926,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0317, 0.0312, 0.0320, 0.0323, 0.2891, 0.0289, 0.0286, 0.4058, 0.3918,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0327, 0.0329, 0.0327, 0.0337, 0.3802, 0.0292, 0.0287, 0.4098, 0.3920,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0344, 0.0330, 0.0337, 0.0328, 0.2558, 0.0294, 0.0287, 0.4120, 0.3927,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0339, 0.0322, 0.0316, 0.0313, 0.4021, 0.0293, 0.0286, 0.4120, 0.3932,\n",
              "          0.4150, 0.5206, 0.3072],\n",
              "         [0.0328, 0.0317, 0.0328, 0.0325, 0.2040, 0.0294, 0.0286, 0.4136, 0.3940,\n",
              "          0.4469, 0.5714, 0.3072],\n",
              "         [0.0329, 0.0319, 0.0329, 0.0320, 0.1729, 0.0294, 0.0286, 0.4143, 0.3948,\n",
              "          0.4541, 0.5765, 0.3072],\n",
              "         [0.0323, 0.0307, 0.0299, 0.0289, 0.2931, 0.0289, 0.0283, 0.4112, 0.3947,\n",
              "          0.4270, 0.4279, 0.3072],\n",
              "         [0.0287, 0.0289, 0.0291, 0.0297, 0.2670, 0.0287, 0.0281, 0.4098, 0.3944,\n",
              "          0.4457, 0.4078, 0.3072],\n",
              "         [0.0304, 0.0288, 0.0294, 0.0288, 0.2157, 0.0283, 0.0278, 0.4077, 0.3936,\n",
              "          0.4102, 0.4058, 0.3072],\n",
              "         [0.0299, 0.0304, 0.0305, 0.0317, 0.2640, 0.0284, 0.0278, 0.4099, 0.3935,\n",
              "          0.5472, 0.5216, 0.3072],\n",
              "         [0.0319, 0.0304, 0.0308, 0.0299, 0.2320, 0.0283, 0.0277, 0.4095, 0.3933,\n",
              "          0.5557, 0.4802, 0.3072],\n",
              "         [0.0307, 0.0292, 0.0296, 0.0297, 0.2226, 0.0281, 0.0276, 0.4091, 0.3931,\n",
              "          0.4983, 0.4140, 0.3072],\n",
              "         [0.0309, 0.0296, 0.0306, 0.0307, 0.1689, 0.0281, 0.0275, 0.4101, 0.3931,\n",
              "          0.5484, 0.4644, 0.3072],\n",
              "         [0.0303, 0.0314, 0.0308, 0.0326, 0.2007, 0.0284, 0.0276, 0.4134, 0.3939,\n",
              "          0.5638, 0.5526, 0.3072],\n",
              "         [0.0333, 0.0320, 0.0323, 0.0314, 0.1867, 0.0285, 0.0276, 0.4146, 0.3948,\n",
              "          0.4767, 0.5749, 0.3072],\n",
              "         [0.0316, 0.0304, 0.0314, 0.0310, 0.2015, 0.0285, 0.0275, 0.4151, 0.3956,\n",
              "          0.4250, 0.5099, 0.3072],\n",
              "         [0.0316, 0.0305, 0.0311, 0.0319, 0.1706, 0.0286, 0.0276, 0.4167, 0.3966,\n",
              "          0.4778, 0.5511, 0.3072],\n",
              "         [0.0317, 0.0311, 0.0317, 0.0324, 0.2198, 0.0288, 0.0277, 0.4186, 0.3978,\n",
              "          0.5383, 0.6079, 0.2795],\n",
              "         [0.0340, 0.0324, 0.0329, 0.0322, 0.1954, 0.0290, 0.0277, 0.4198, 0.3990,\n",
              "          0.4925, 0.6847, 0.2672]]),\n",
              " tensor([0.0327, 0.0312, 0.0323, 0.0316, 0.1261, 0.0290, 0.0277, 0.4202, 0.4001,\n",
              "         0.4916, 0.6115, 0.2574]))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0], y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_bkGVmnU44s"
      },
      "outputs": [],
      "source": [
        "### build LSTM model\n",
        "\n",
        "class LSTMv0(nn.Module):\n",
        "    def __init__(self, input_features, hidden_features, num_layers, output_features):\n",
        "        super().__init__()\n",
        "        self.hidden_features = hidden_features\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_features, hidden_features, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_features, output_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_features)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_features)\n",
        "\n",
        "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out)\n",
        "        return out[:, -1, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REIzbeqnU44t"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "INPUT_FEATURES = len(X_train[0, 0, :])\n",
        "HIDDEN_FEATURES = 30\n",
        "NUM_LAYERS = 3\n",
        "OUTPUT_FEATURES = len(y_train[0, :])\n",
        "\n",
        "model_0 = LSTMv0(INPUT_FEATURES, HIDDEN_FEATURES, NUM_LAYERS, OUTPUT_FEATURES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qS73MlktU44t",
        "outputId": "9332fdfa-b0a5-48f6-a8c6-31eec13e5703"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LSTMv0(\n",
              "  (lstm): LSTM(12, 30, num_layers=3, batch_first=True)\n",
              "  (fc): Linear(in_features=30, out_features=12, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGorOrc_U44u"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgdYA6FDU44u",
        "outputId": "6ea736ac-c9bf-4099-8da1-1d2689e1eba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 | Loss: 0.1438 | Test Loss: 0.3873\n",
            "Epoch: 20 | Loss: 0.1343 | Test Loss: 0.3722\n",
            "Epoch: 40 | Loss: 0.1255 | Test Loss: 0.3583\n",
            "Epoch: 60 | Loss: 0.1176 | Test Loss: 0.3453\n",
            "Epoch: 80 | Loss: 0.1102 | Test Loss: 0.3332\n",
            "Epoch: 100 | Loss: 0.1036 | Test Loss: 0.3219\n",
            "Epoch: 120 | Loss: 0.0974 | Test Loss: 0.3113\n",
            "Epoch: 140 | Loss: 0.0918 | Test Loss: 0.3014\n",
            "Epoch: 160 | Loss: 0.0867 | Test Loss: 0.2922\n",
            "Epoch: 180 | Loss: 0.0819 | Test Loss: 0.2836\n"
          ]
        }
      ],
      "source": [
        "# training loop\n",
        "epochs = 200\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # train mode\n",
        "    model_0.train()\n",
        "\n",
        "    # forward pass\n",
        "    y_pred = model_0(X_train)\n",
        "\n",
        "    # calulate loss\n",
        "    loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "    # optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # backward\n",
        "    loss.backward()\n",
        "\n",
        "    # step optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "    model_0.eval()\n",
        "    with torch.inference_mode():\n",
        "        test_pred = model_0(X_test)\n",
        "        test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "    # print\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"Epoch: {epoch} | Loss: {loss:.4f} | Test Loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymOHi-UfU44v",
        "outputId": "76187b98-7393-4f0a-9aca-944eb987b8a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.1817,  0.0841,  0.0656,  0.0115,  0.0249,  0.1987, -0.0058,  0.1386,\n",
              "          0.2414,  0.3063,  0.2020,  0.0855],\n",
              "        [ 0.1817,  0.0841,  0.0656,  0.0114,  0.0248,  0.1989, -0.0059,  0.1386,\n",
              "          0.2412,  0.3063,  0.2020,  0.0854],\n",
              "        [ 0.1817,  0.0840,  0.0657,  0.0113,  0.0247,  0.1991, -0.0059,  0.1386,\n",
              "          0.2412,  0.3063,  0.2020,  0.0853],\n",
              "        [ 0.1818,  0.0840,  0.0657,  0.0112,  0.0247,  0.1992, -0.0060,  0.1386,\n",
              "          0.2412,  0.3062,  0.2020,  0.0853],\n",
              "        [ 0.1818,  0.0840,  0.0656,  0.0112,  0.0247,  0.1993, -0.0060,  0.1386,\n",
              "          0.2412,  0.3063,  0.2020,  0.0853]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate model with test values\n",
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "    eval_pred = model_0(X_test)\n",
        "eval_pred[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFMgYlqyU44v",
        "outputId": "4bb833c5-5a56-4f7a-f9fc-e78ca271ee8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.1838,  0.0838,  0.0634,  0.0108,  0.0244,  0.2005, -0.0067,  0.1374,\n",
              "          0.2425,  0.3060,  0.2017,  0.0864],\n",
              "        [ 0.1839,  0.0837,  0.0633,  0.0108,  0.0245,  0.2004, -0.0067,  0.1373,\n",
              "          0.2428,  0.3058,  0.2015,  0.0864],\n",
              "        [ 0.1839,  0.0836,  0.0634,  0.0107,  0.0245,  0.2004, -0.0067,  0.1372,\n",
              "          0.2430,  0.3055,  0.2014,  0.0864],\n",
              "        [ 0.1840,  0.0835,  0.0635,  0.0106,  0.0245,  0.2004, -0.0066,  0.1371,\n",
              "          0.2432,  0.3053,  0.2012,  0.0864],\n",
              "        [ 0.1840,  0.0834,  0.0635,  0.0105,  0.0246,  0.2004, -0.0066,  0.1370,\n",
              "          0.2434,  0.3051,  0.2011,  0.0865]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_pred[-5: ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vq9QtGiU44w"
      },
      "source": [
        "### **Start from scratch**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTZTh_jVU44x"
      },
      "source": [
        "**Plan**\n",
        "1. Make LSTM function that can be used to fit different dataframes, and Train in seperately\n",
        "2. Make Stock Trading Env\n",
        "3. Use Stable_Baselines3 to import PPO model, and Trian it with LSTM(that are trained before)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVNygFa4U44x"
      },
      "outputs": [],
      "source": [
        "# ## Make a function that can take data and break-down it into different dataframes (or inputs)\n",
        "\n",
        "# import pandas as pd\n",
        "# import torch\n",
        "# import torch.nn.functional as F\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# def data_fragmenter(df: pd.DataFrame):\n",
        "#     scaler = MinMaxScaler()\n",
        "#     df_fundamental = df[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "#     df_mavg = df[[\"EMA_12\", \"EMA_26\"]]\n",
        "#     df_mi = df[[\"MACD\", \"Signal\", \"RSI\", \"CCI\"]]\n",
        "#     df_adx = df[[\"ADX\"]]\n",
        "\n",
        "#     # normalize\n",
        "#     df_fundamental = scaler.fit_transform(df_fundamental)\n",
        "#     df_mavg = scaler.fit_transform(df_mavg)\n",
        "#     df_mi = scaler.fit_transform(df_mi)\n",
        "#     df_adx = scaler.fit_transform(df_adx)\n",
        "\n",
        "#     return df_fundamental, df_mavg, df_mi, df_adx\n",
        "\n",
        "# df = pd.read_csv(\"./stocks_data/AAPL_data.csv\")\n",
        "# fundamental, mavg, mi, adx = data_fragmenter(df=df)\n",
        "# fundamental[:5], mavg[:5], mi[:5], adx[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq8DfhbmU44y"
      },
      "source": [
        "Break Down data into columns or dataframes\n",
        "1. Open, High, Low, Close, Volume -> Fundamental Data\n",
        "2. EMA_12, EMA_26 -> Moving Avgs\n",
        "3. MACD, Signal, RSI, CCI -> Momentum Indicators\n",
        "4. ADX -> Trend Strength (ADX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5s0mlPnU-UF",
        "outputId": "3e068078-8f2f-41de-e327-d1cf7f35b2b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'major_project'...\n",
            "remote: Enumerating objects: 147, done.\u001b[K\n",
            "remote: Total 147 (delta 0), reused 0 (delta 0), pack-reused 147 (from 1)\u001b[K\n",
            "Receiving objects: 100% (147/147), 29.99 MiB | 11.93 MiB/s, done.\n",
            "Resolving deltas: 100% (69/69), done.\n"
          ]
        }
      ],
      "source": [
        "# !git clone \"https://github.com/MRR20/major_project.git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "b0x-J3OKVjs3"
      },
      "outputs": [],
      "source": [
        "# !cd ./major_project/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gU4-HnUVp0F",
        "outputId": "9f9fdc20-296c-45a4-c235-c618416ef934"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/major_project/stocks_data.zip\n",
            "   creating: /content/stocks_data/\n",
            "   creating: /content/stocks_data/.ipynb_checkpoints/\n",
            "  inflating: /content/stocks_data/.ipynb_checkpoints/AAPL_data-checkpoint.csv  \n",
            "  inflating: /content/stocks_data/.ipynb_checkpoints/AMGN_data-checkpoint.csv  \n",
            "  inflating: /content/stocks_data/AAPL_data.csv  \n",
            "  inflating: /content/stocks_data/AMGN_data.csv  \n",
            "  inflating: /content/stocks_data/AXP_data.csv  \n",
            "  inflating: /content/stocks_data/BA_data.csv  \n",
            "  inflating: /content/stocks_data/CAT_data.csv  \n",
            "  inflating: /content/stocks_data/CRM_data.csv  \n",
            "  inflating: /content/stocks_data/CSCO_data.csv  \n",
            "  inflating: /content/stocks_data/CVX_data.csv  \n",
            "  inflating: /content/stocks_data/DIS_data.csv  \n",
            "  inflating: /content/stocks_data/DOW_data.csv  \n",
            "  inflating: /content/stocks_data/GS_data.csv  \n",
            "  inflating: /content/stocks_data/HD_data.csv  \n",
            "  inflating: /content/stocks_data/HON_data.csv  \n",
            "  inflating: /content/stocks_data/IBM_data.csv  \n",
            "  inflating: /content/stocks_data/INTC_data.csv  \n",
            "  inflating: /content/stocks_data/JNJ_data.csv  \n",
            "  inflating: /content/stocks_data/JPM_data.csv  \n",
            "  inflating: /content/stocks_data/KO_data.csv  \n",
            "  inflating: /content/stocks_data/MCD_data.csv  \n",
            "  inflating: /content/stocks_data/MMM_data.csv  \n",
            "  inflating: /content/stocks_data/MRK_data.csv  \n",
            "  inflating: /content/stocks_data/MSFT_data.csv  \n",
            "  inflating: /content/stocks_data/NKE_data.csv  \n",
            "  inflating: /content/stocks_data/PG_data.csv  \n",
            "  inflating: /content/stocks_data/TRV_data.csv  \n",
            "  inflating: /content/stocks_data/UNH_data.csv  \n",
            "  inflating: /content/stocks_data/VZ_data.csv  \n",
            "  inflating: /content/stocks_data/V_data.csv  \n",
            "  inflating: /content/stocks_data/WBA_data.csv  \n",
            "  inflating: /content/stocks_data/WMT_data.csv  \n"
          ]
        }
      ],
      "source": [
        "# !unzip \"/content/major_project/stocks_data.zip\" -d \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "F0WbnLFVU44y",
        "outputId": "e1cecb4d-6db3-4443-a031-7e1171546086"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Jkr243zYU44z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def data_sequencer(data: torch.Tensor, sequence_len: int, device=\"cpu\"):\n",
        "    xs = []\n",
        "    ys = []\n",
        "\n",
        "    for i in range(len(data) - sequence_len):\n",
        "        xs.append(data[i: i+sequence_len])\n",
        "        ys.append(data[i+sequence_len])\n",
        "\n",
        "    xs = np.array(xs)\n",
        "    ys = np.array(ys)\n",
        "\n",
        "    xs = torch.tensor(xs, dtype=torch.float32, device=device)\n",
        "    ys = torch.tensor(ys, dtype=torch.float32, device=device)\n",
        "\n",
        "    return xs, ys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_ILK5ksYU44z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def data_fragmenter(df: pd.DataFrame, device=\"cpu\"):\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    df_fundamental = df[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "    df_mavg = df[[\"EMA_12\", \"EMA_26\"]]\n",
        "    df_mi = df[[\"MACD\", \"Signal\", \"RSI\", \"CCI\"]]\n",
        "    df_adx = df[[\"ADX\"]]\n",
        "\n",
        "    # normalize\n",
        "    df_fundamental = scaler.fit_transform(df_fundamental)\n",
        "    df_mavg = scaler.fit_transform(df_mavg)\n",
        "    df_mi = scaler.fit_transform(df_mi)\n",
        "    df_adx = scaler.fit_transform(df_adx)\n",
        "\n",
        "    fundamental_x, fundamental_y = data_sequencer(df_fundamental, 30, device=device)\n",
        "    mavg_x, mavg_y = data_sequencer(df_mavg, 30, device=device)\n",
        "    mi_x, mi_y = data_sequencer(df_mi, 30, device=device)\n",
        "    adx_x, adx_y = data_sequencer(df_adx, 30, device=device)\n",
        "\n",
        "    return fundamental_x, fundamental_y, mavg_x, mavg_y, mi_x, mi_y, adx_x, adx_y\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"./stocks_data/AAPL_data.csv\")\n",
        "fundamental_x, fundamental_y, mavg_x, mavg_y, mi_x, mi_y, adx_x, adx_y = data_fragmenter(df=df, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SZfG-KqNU44z"
      },
      "outputs": [],
      "source": [
        "## Make LSTM that can adapt to shape of data\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class LSTMv1(nn.Module):\n",
        "    def __init__(self, input_features, hidden_features, num_layers, output_features, device=\"cpu\"):\n",
        "        super().__init__()\n",
        "        self.hidden_features = hidden_features\n",
        "        self.num_layers = num_layers\n",
        "        self.device = device\n",
        "\n",
        "        self.lstm = nn.LSTM(input_features, hidden_features, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_features, output_features)\n",
        "        self.to(device=device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_features, device=self.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_features, device=self.device)\n",
        "\n",
        "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out)\n",
        "        return out[:, -1, :]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FIlN04txU440"
      },
      "outputs": [],
      "source": [
        "# INPUT_FEATURES = len(X_train[0, 0, :])\n",
        "# HIDDEN_FEATURES = 30\n",
        "# NUM_LAYERS = 3\n",
        "# OUTPUT_FEATURES = len(y_train[0, :])\n",
        "\n",
        "model_fundamental = LSTMv1(len(fundamental_x[0, 0, :]), hidden_features=128, num_layers=3, output_features=len(fundamental_y[0, :]), device=device)\n",
        "model_mavg = LSTMv1(len(mavg_x[0, 0, :]), hidden_features=128, num_layers=3, output_features=len(mavg_y[0, :]), device=device)\n",
        "model_mi = LSTMv1(len(mi_x[0, 0, :]), hidden_features=128, num_layers=3, output_features=len(mi_y[0, :]), device=device)\n",
        "model_adx = LSTMv1(len(adx_x[0, 0, :]), hidden_features=128, num_layers=3, output_features=len(adx_y[0, :]), device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGJ3lFgwU440",
        "outputId": "149b65f3-1e86-44a8-8989-f184254cd04f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(LSTMv1(\n",
              "   (lstm): LSTM(5, 128, num_layers=3, batch_first=True)\n",
              "   (fc): Linear(in_features=128, out_features=5, bias=True)\n",
              " ),\n",
              " LSTMv1(\n",
              "   (lstm): LSTM(2, 128, num_layers=3, batch_first=True)\n",
              "   (fc): Linear(in_features=128, out_features=2, bias=True)\n",
              " ),\n",
              " LSTMv1(\n",
              "   (lstm): LSTM(4, 128, num_layers=3, batch_first=True)\n",
              "   (fc): Linear(in_features=128, out_features=4, bias=True)\n",
              " ),\n",
              " LSTMv1(\n",
              "   (lstm): LSTM(1, 128, num_layers=3, batch_first=True)\n",
              "   (fc): Linear(in_features=128, out_features=1, bias=True)\n",
              " ))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_fundamental, model_mavg, model_mi, model_adx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lnwTG8apU440"
      },
      "outputs": [],
      "source": [
        "fundamental_loss_fn = nn.MSELoss().to(device)\n",
        "mavg_loss_fn = nn.MSELoss().to(device)\n",
        "mi_loss_fn = nn.MSELoss().to(device)\n",
        "adx_loss_fn = nn.MSELoss().to(device)\n",
        "\n",
        "optimizer_fundamental = torch.optim.Adam(params=model_fundamental.parameters(), lr=0.0001)\n",
        "optimizer_mavg = torch.optim.Adam(params=model_mavg.parameters(), lr=0.0001)\n",
        "optimizer_mi = torch.optim.Adam(params=model_mi.parameters(), lr=0.0001)\n",
        "optimizer_adx = torch.optim.Adam(params=model_adx.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "enbfMYmwU441",
        "outputId": "ec6d50ae-943f-4b29-a8e8-909c60fd0743"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'TRV_data.csv'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Alternate training\n",
        "import random\n",
        "import os\n",
        "file = random.choice(os.listdir(\"./stocks_data\"))\n",
        "file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXV7Jb-7U441"
      },
      "source": [
        "1. Pick a random file\n",
        "2. read csv data as df\n",
        "3. process df with data_fragmenter()\n",
        "4. provide inputs to model\n",
        "5. train certain epochs(10) with data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_y_i2upU441",
        "outputId": "86d5d7c1-b96d-4ae1-c5f6-c5f65b7a0ff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fundamental Model -> Epoch: 0 | Loss: 0.026936253532767296\n",
            "MAVG Model -> Epoch: 0 | Loss: 0.0369601771235466\n",
            "MI Model -> Epoch: 0 | Loss: 0.023501908406615257\n",
            "ADX Model -> Epoch: 0 | Loss: 0.026565583422780037\n",
            "\n",
            "Fundamental Model -> Epoch: 100 | Loss: 0.003921386320143938\n",
            "MAVG Model -> Epoch: 100 | Loss: 0.0044388980604708195\n",
            "MI Model -> Epoch: 100 | Loss: 0.016537750139832497\n",
            "ADX Model -> Epoch: 100 | Loss: 0.025254735723137856\n",
            "\n",
            "Fundamental Model -> Epoch: 200 | Loss: 0.0024632420390844345\n",
            "MAVG Model -> Epoch: 200 | Loss: 0.0019426963990554214\n",
            "MI Model -> Epoch: 200 | Loss: 0.014128012582659721\n",
            "ADX Model -> Epoch: 200 | Loss: 0.007126267533749342\n",
            "\n",
            "Fundamental Model -> Epoch: 300 | Loss: 0.004440163262188435\n",
            "MAVG Model -> Epoch: 300 | Loss: 0.0023170888889580965\n",
            "MI Model -> Epoch: 300 | Loss: 0.016871999949216843\n",
            "ADX Model -> Epoch: 300 | Loss: 0.0028229071758687496\n",
            "\n",
            "Fundamental Model -> Epoch: 400 | Loss: 0.003757881000638008\n",
            "MAVG Model -> Epoch: 400 | Loss: 0.0017666991334408522\n",
            "MI Model -> Epoch: 400 | Loss: 0.01293766126036644\n",
            "ADX Model -> Epoch: 400 | Loss: 0.0036087704356759787\n",
            "\n",
            "Fundamental Model -> Epoch: 500 | Loss: 0.001935986801981926\n",
            "MAVG Model -> Epoch: 500 | Loss: 0.0005148428026586771\n",
            "MI Model -> Epoch: 500 | Loss: 0.012171221897006035\n",
            "ADX Model -> Epoch: 500 | Loss: 0.0019335915567353368\n",
            "\n",
            "Fundamental Model -> Epoch: 600 | Loss: 0.007433926220983267\n",
            "MAVG Model -> Epoch: 600 | Loss: 0.002538159256801009\n",
            "MI Model -> Epoch: 600 | Loss: 0.015239116735756397\n",
            "ADX Model -> Epoch: 600 | Loss: 0.002100690035149455\n",
            "\n",
            "Fundamental Model -> Epoch: 700 | Loss: 0.0028714933432638645\n",
            "MAVG Model -> Epoch: 700 | Loss: 0.00025783744058571756\n",
            "MI Model -> Epoch: 700 | Loss: 0.009886770509183407\n",
            "ADX Model -> Epoch: 700 | Loss: 0.001325883436948061\n",
            "\n",
            "Fundamental Model -> Epoch: 800 | Loss: 0.0016779820434749126\n",
            "MAVG Model -> Epoch: 800 | Loss: 0.000237584303249605\n",
            "MI Model -> Epoch: 800 | Loss: 0.010182954370975494\n",
            "ADX Model -> Epoch: 800 | Loss: 0.0009174029109999537\n",
            "\n",
            "Fundamental Model -> Epoch: 900 | Loss: 0.003878326155245304\n",
            "MAVG Model -> Epoch: 900 | Loss: 0.001341233029961586\n",
            "MI Model -> Epoch: 900 | Loss: 0.008774591609835625\n",
            "ADX Model -> Epoch: 900 | Loss: 0.0008758182520978153\n",
            "\n",
            "Fundamental Model -> Epoch: 1100 | Loss: 0.002811953891068697\n",
            "MAVG Model -> Epoch: 1100 | Loss: 0.0011814376339316368\n",
            "MI Model -> Epoch: 1100 | Loss: 0.009106900542974472\n",
            "ADX Model -> Epoch: 1100 | Loss: 0.0007357960566878319\n",
            "\n",
            "Fundamental Model -> Epoch: 1200 | Loss: 0.0014008539728820324\n",
            "MAVG Model -> Epoch: 1200 | Loss: 0.00015902845188975334\n",
            "MI Model -> Epoch: 1200 | Loss: 0.010610884986817837\n",
            "ADX Model -> Epoch: 1200 | Loss: 0.000602445041295141\n",
            "\n",
            "Fundamental Model -> Epoch: 1300 | Loss: 0.0028167355339974165\n",
            "MAVG Model -> Epoch: 1300 | Loss: 0.00032679259311407804\n",
            "MI Model -> Epoch: 1300 | Loss: 0.007378910202533007\n",
            "ADX Model -> Epoch: 1300 | Loss: 0.0006646906840614974\n",
            "\n",
            "Fundamental Model -> Epoch: 1400 | Loss: 0.0033630302641540766\n",
            "MAVG Model -> Epoch: 1400 | Loss: 0.00022985816758591682\n",
            "MI Model -> Epoch: 1400 | Loss: 0.008085956797003746\n",
            "ADX Model -> Epoch: 1400 | Loss: 0.0006858863052912056\n",
            "\n",
            "Fundamental Model -> Epoch: 1500 | Loss: 0.003314582398161292\n",
            "MAVG Model -> Epoch: 1500 | Loss: 0.0008210005471482873\n",
            "MI Model -> Epoch: 1500 | Loss: 0.0069420854561030865\n",
            "ADX Model -> Epoch: 1500 | Loss: 0.0005730856209993362\n",
            "\n",
            "Fundamental Model -> Epoch: 1600 | Loss: 0.0017595411045476794\n",
            "MAVG Model -> Epoch: 1600 | Loss: 0.0002442531113047153\n",
            "MI Model -> Epoch: 1600 | Loss: 0.00656827911734581\n",
            "ADX Model -> Epoch: 1600 | Loss: 0.0005193355609662831\n",
            "\n",
            "Fundamental Model -> Epoch: 1700 | Loss: 0.0013196682557463646\n",
            "MAVG Model -> Epoch: 1700 | Loss: 0.00026774650905281305\n",
            "MI Model -> Epoch: 1700 | Loss: 0.006324043497443199\n",
            "ADX Model -> Epoch: 1700 | Loss: 0.0004937718622386456\n",
            "\n",
            "Fundamental Model -> Epoch: 1800 | Loss: 0.0033533493988215923\n",
            "MAVG Model -> Epoch: 1800 | Loss: 0.0005481743719428778\n",
            "MI Model -> Epoch: 1800 | Loss: 0.006078937090933323\n",
            "ADX Model -> Epoch: 1800 | Loss: 0.0005862169782631099\n",
            "\n",
            "Fundamental Model -> Epoch: 1900 | Loss: 0.001970927696675062\n",
            "MAVG Model -> Epoch: 1900 | Loss: 0.00013693427899852395\n",
            "MI Model -> Epoch: 1900 | Loss: 0.006504043471068144\n",
            "ADX Model -> Epoch: 1900 | Loss: 0.0005322550423443317\n",
            "\n",
            "Fundamental Model -> Epoch: 2000 | Loss: 0.0023781240452080965\n",
            "MAVG Model -> Epoch: 2000 | Loss: 0.00019395510025788099\n",
            "MI Model -> Epoch: 2000 | Loss: 0.004711872432380915\n",
            "ADX Model -> Epoch: 2000 | Loss: 0.0005495432415045798\n",
            "\n",
            "Fundamental Model -> Epoch: 2100 | Loss: 0.0017482503317296505\n",
            "MAVG Model -> Epoch: 2100 | Loss: 0.00032168833422474563\n",
            "MI Model -> Epoch: 2100 | Loss: 0.00474303076043725\n",
            "ADX Model -> Epoch: 2100 | Loss: 0.0004974653711542487\n",
            "\n",
            "Fundamental Model -> Epoch: 2200 | Loss: 0.0017213313840329647\n",
            "MAVG Model -> Epoch: 2200 | Loss: 0.0001290318468818441\n",
            "MI Model -> Epoch: 2200 | Loss: 0.005997374188154936\n",
            "ADX Model -> Epoch: 2200 | Loss: 0.0004384213825687766\n",
            "\n",
            "Fundamental Model -> Epoch: 2300 | Loss: 0.001967540243640542\n",
            "MAVG Model -> Epoch: 2300 | Loss: 0.00010347661736886948\n",
            "MI Model -> Epoch: 2300 | Loss: 0.004715689457952976\n",
            "ADX Model -> Epoch: 2300 | Loss: 0.00043165625538676977\n",
            "\n",
            "Fundamental Model -> Epoch: 2400 | Loss: 0.001136898179538548\n",
            "MAVG Model -> Epoch: 2400 | Loss: 5.999131826683879e-05\n",
            "MI Model -> Epoch: 2400 | Loss: 0.007130721118301153\n",
            "ADX Model -> Epoch: 2400 | Loss: 0.0003185382520314306\n",
            "\n",
            "Fundamental Model -> Epoch: 2500 | Loss: 0.001177030149847269\n",
            "MAVG Model -> Epoch: 2500 | Loss: 0.00022501629428006709\n",
            "MI Model -> Epoch: 2500 | Loss: 0.004744770936667919\n",
            "ADX Model -> Epoch: 2500 | Loss: 0.00037146254908293486\n",
            "\n",
            "Fundamental Model -> Epoch: 2600 | Loss: 0.0025948018301278353\n",
            "MAVG Model -> Epoch: 2600 | Loss: 0.00041482222150079906\n",
            "MI Model -> Epoch: 2600 | Loss: 0.004362557083368301\n",
            "ADX Model -> Epoch: 2600 | Loss: 0.00028132295119576156\n",
            "\n",
            "Fundamental Model -> Epoch: 2700 | Loss: 0.001085277646780014\n",
            "MAVG Model -> Epoch: 2700 | Loss: 0.00018489510694053024\n",
            "MI Model -> Epoch: 2700 | Loss: 0.003947811666876078\n",
            "ADX Model -> Epoch: 2700 | Loss: 0.0005502295680344105\n",
            "\n",
            "Fundamental Model -> Epoch: 2800 | Loss: 0.0013183123664930463\n",
            "MAVG Model -> Epoch: 2800 | Loss: 0.00010770367225632071\n",
            "MI Model -> Epoch: 2800 | Loss: 0.0036232667043805122\n",
            "ADX Model -> Epoch: 2800 | Loss: 0.00030276222969405353\n",
            "\n",
            "Fundamental Model -> Epoch: 2900 | Loss: 0.0007841623155400157\n",
            "MAVG Model -> Epoch: 2900 | Loss: 0.00013090977154206485\n",
            "MI Model -> Epoch: 2900 | Loss: 0.0035635437816381454\n",
            "ADX Model -> Epoch: 2900 | Loss: 0.0005494461511261761\n",
            "\n",
            "Fundamental Model -> Epoch: 3000 | Loss: 0.0019033363787457347\n",
            "MAVG Model -> Epoch: 3000 | Loss: 9.311707253800705e-05\n",
            "MI Model -> Epoch: 3000 | Loss: 0.0032970071770250797\n",
            "ADX Model -> Epoch: 3000 | Loss: 0.00033448211615905166\n",
            "\n",
            "Fundamental Model -> Epoch: 3100 | Loss: 0.0012456111144274473\n",
            "MAVG Model -> Epoch: 3100 | Loss: 0.00015126747894100845\n",
            "MI Model -> Epoch: 3100 | Loss: 0.003854493610560894\n",
            "ADX Model -> Epoch: 3100 | Loss: 0.0003567140956874937\n",
            "\n",
            "Fundamental Model -> Epoch: 3200 | Loss: 0.0021392162889242172\n",
            "MAVG Model -> Epoch: 3200 | Loss: 0.00010378896695328876\n",
            "MI Model -> Epoch: 3200 | Loss: 0.004581701010465622\n",
            "ADX Model -> Epoch: 3200 | Loss: 0.00030051294015720487\n",
            "\n",
            "Fundamental Model -> Epoch: 3300 | Loss: 0.0007390649989247322\n",
            "MAVG Model -> Epoch: 3300 | Loss: 0.00011708603415172547\n",
            "MI Model -> Epoch: 3300 | Loss: 0.0039441813714802265\n",
            "ADX Model -> Epoch: 3300 | Loss: 0.0004786499193869531\n",
            "\n",
            "Fundamental Model -> Epoch: 3400 | Loss: 0.0006017411360517144\n",
            "MAVG Model -> Epoch: 3400 | Loss: 6.927963113412261e-05\n",
            "MI Model -> Epoch: 3400 | Loss: 0.003466244786977768\n",
            "ADX Model -> Epoch: 3400 | Loss: 0.00032282702159136534\n",
            "\n",
            "Fundamental Model -> Epoch: 3500 | Loss: 0.001149964053183794\n",
            "MAVG Model -> Epoch: 3500 | Loss: 7.32487314962782e-05\n",
            "MI Model -> Epoch: 3500 | Loss: 0.0036760244984179735\n",
            "ADX Model -> Epoch: 3500 | Loss: 0.00025831020320765674\n",
            "\n",
            "Fundamental Model -> Epoch: 3600 | Loss: 0.0007806337089277804\n",
            "MAVG Model -> Epoch: 3600 | Loss: 6.997418677201495e-05\n",
            "MI Model -> Epoch: 3600 | Loss: 0.0039668153040111065\n",
            "ADX Model -> Epoch: 3600 | Loss: 0.000292027834802866\n",
            "\n",
            "Fundamental Model -> Epoch: 3700 | Loss: 0.0013447896344587207\n",
            "MAVG Model -> Epoch: 3700 | Loss: 4.043173976242542e-05\n",
            "MI Model -> Epoch: 3700 | Loss: 0.0035132409539073706\n",
            "ADX Model -> Epoch: 3700 | Loss: 0.0002842359244823456\n",
            "\n",
            "Fundamental Model -> Epoch: 3800 | Loss: 0.0007831763941794634\n",
            "MAVG Model -> Epoch: 3800 | Loss: 6.369288894347847e-05\n",
            "MI Model -> Epoch: 3800 | Loss: 0.004281819332391024\n",
            "ADX Model -> Epoch: 3800 | Loss: 0.00025350210489705205\n",
            "\n",
            "Fundamental Model -> Epoch: 3900 | Loss: 0.0016696328530088067\n",
            "MAVG Model -> Epoch: 3900 | Loss: 0.00018589600222185254\n",
            "MI Model -> Epoch: 3900 | Loss: 0.003505883738398552\n",
            "ADX Model -> Epoch: 3900 | Loss: 0.00028593745082616806\n",
            "\n",
            "Fundamental Model -> Epoch: 4000 | Loss: 0.002161871874704957\n",
            "MAVG Model -> Epoch: 4000 | Loss: 0.00024020412820391357\n",
            "MI Model -> Epoch: 4000 | Loss: 0.00345627311617136\n",
            "ADX Model -> Epoch: 4000 | Loss: 0.00022431046818383038\n",
            "\n",
            "Fundamental Model -> Epoch: 4100 | Loss: 0.001791980816051364\n",
            "MAVG Model -> Epoch: 4100 | Loss: 7.961825031088665e-05\n",
            "MI Model -> Epoch: 4100 | Loss: 0.003089526202529669\n",
            "ADX Model -> Epoch: 4100 | Loss: 0.00033897047978825867\n",
            "\n",
            "Fundamental Model -> Epoch: 4200 | Loss: 0.0010607743170112371\n",
            "MAVG Model -> Epoch: 4200 | Loss: 3.583585566957481e-05\n",
            "MI Model -> Epoch: 4200 | Loss: 0.005696981679648161\n",
            "ADX Model -> Epoch: 4200 | Loss: 0.00022831629030406475\n",
            "\n",
            "Fundamental Model -> Epoch: 4300 | Loss: 0.0021065110340714455\n",
            "MAVG Model -> Epoch: 4300 | Loss: 8.162580343196169e-05\n",
            "MI Model -> Epoch: 4300 | Loss: 0.0037361716385930777\n",
            "ADX Model -> Epoch: 4300 | Loss: 0.0002780235081445426\n",
            "\n",
            "Fundamental Model -> Epoch: 4400 | Loss: 0.0007620147662237287\n",
            "MAVG Model -> Epoch: 4400 | Loss: 0.00021750984888058156\n",
            "MI Model -> Epoch: 4400 | Loss: 0.0032223104499280453\n",
            "ADX Model -> Epoch: 4400 | Loss: 0.000258795014815405\n",
            "\n",
            "Fundamental Model -> Epoch: 4500 | Loss: 0.0021868294570595026\n",
            "MAVG Model -> Epoch: 4500 | Loss: 3.976512743975036e-05\n",
            "MI Model -> Epoch: 4500 | Loss: 0.00345963379368186\n",
            "ADX Model -> Epoch: 4500 | Loss: 0.000234475897741504\n",
            "\n",
            "Fundamental Model -> Epoch: 4600 | Loss: 0.0012311098398640752\n",
            "MAVG Model -> Epoch: 4600 | Loss: 7.488705887226388e-05\n",
            "MI Model -> Epoch: 4600 | Loss: 0.0031554631423205137\n",
            "ADX Model -> Epoch: 4600 | Loss: 0.0002518490655347705\n",
            "\n",
            "Fundamental Model -> Epoch: 4700 | Loss: 0.0013224688591435552\n",
            "MAVG Model -> Epoch: 4700 | Loss: 3.2076331990538165e-05\n",
            "MI Model -> Epoch: 4700 | Loss: 0.003234598319977522\n",
            "ADX Model -> Epoch: 4700 | Loss: 0.0002787515986710787\n",
            "\n",
            "Fundamental Model -> Epoch: 4800 | Loss: 0.0016965584363788366\n",
            "MAVG Model -> Epoch: 4800 | Loss: 4.286221883376129e-05\n",
            "MI Model -> Epoch: 4800 | Loss: 0.003446143353357911\n",
            "ADX Model -> Epoch: 4800 | Loss: 0.0003023634199053049\n",
            "\n",
            "Fundamental Model -> Epoch: 4900 | Loss: 0.0006360024563036859\n",
            "MAVG Model -> Epoch: 4900 | Loss: 8.266688382718712e-05\n",
            "MI Model -> Epoch: 4900 | Loss: 0.0031533525325357914\n",
            "ADX Model -> Epoch: 4900 | Loss: 0.0002470637846272439\n",
            "\n",
            "Fundamental Model -> Epoch: 5000 | Loss: 0.0005793952150270343\n",
            "MAVG Model -> Epoch: 5000 | Loss: 3.6979912692913786e-05\n",
            "MI Model -> Epoch: 5000 | Loss: 0.0032612429931759834\n",
            "ADX Model -> Epoch: 5000 | Loss: 0.00033275625901296735\n",
            "\n",
            "Fundamental Model -> Epoch: 5100 | Loss: 0.0012031728401780128\n",
            "MAVG Model -> Epoch: 5100 | Loss: 3.05011108139297e-05\n",
            "MI Model -> Epoch: 5100 | Loss: 0.003831382840871811\n",
            "ADX Model -> Epoch: 5100 | Loss: 0.00028268492314964533\n",
            "\n",
            "Fundamental Model -> Epoch: 5200 | Loss: 0.00040599412750452757\n",
            "MAVG Model -> Epoch: 5200 | Loss: 3.550712062860839e-05\n",
            "MI Model -> Epoch: 5200 | Loss: 0.003606271930038929\n",
            "ADX Model -> Epoch: 5200 | Loss: 0.00023478308867197484\n",
            "\n",
            "Fundamental Model -> Epoch: 5300 | Loss: 0.000908849120605737\n",
            "MAVG Model -> Epoch: 5300 | Loss: 0.00017940982070285827\n",
            "MI Model -> Epoch: 5300 | Loss: 0.004477051552385092\n",
            "ADX Model -> Epoch: 5300 | Loss: 0.00023163142031989992\n",
            "\n",
            "Fundamental Model -> Epoch: 5400 | Loss: 0.0005463766865432262\n",
            "MAVG Model -> Epoch: 5400 | Loss: 3.3180891477968544e-05\n",
            "MI Model -> Epoch: 5400 | Loss: 0.00315235392190516\n",
            "ADX Model -> Epoch: 5400 | Loss: 0.00032710074447095394\n",
            "\n",
            "Fundamental Model -> Epoch: 5500 | Loss: 0.0005359720671549439\n",
            "MAVG Model -> Epoch: 5500 | Loss: 6.0149173805257306e-05\n",
            "MI Model -> Epoch: 5500 | Loss: 0.0032061273232102394\n",
            "ADX Model -> Epoch: 5500 | Loss: 0.00031817605486139655\n",
            "\n",
            "Fundamental Model -> Epoch: 5600 | Loss: 0.0008042010595090687\n",
            "MAVG Model -> Epoch: 5600 | Loss: 0.0001353075058432296\n",
            "MI Model -> Epoch: 5600 | Loss: 0.003050896804779768\n",
            "ADX Model -> Epoch: 5600 | Loss: 0.0003399740089662373\n",
            "\n",
            "Fundamental Model -> Epoch: 5700 | Loss: 0.0020866564009338617\n",
            "MAVG Model -> Epoch: 5700 | Loss: 5.082259303890169e-05\n",
            "MI Model -> Epoch: 5700 | Loss: 0.005298427306115627\n",
            "ADX Model -> Epoch: 5700 | Loss: 0.00023179809795692563\n",
            "\n",
            "Fundamental Model -> Epoch: 5800 | Loss: 0.0007728946511633694\n",
            "MAVG Model -> Epoch: 5800 | Loss: 0.00015512132085859776\n",
            "MI Model -> Epoch: 5800 | Loss: 0.002913886681199074\n",
            "ADX Model -> Epoch: 5800 | Loss: 0.00032798293977975845\n",
            "\n",
            "Fundamental Model -> Epoch: 5900 | Loss: 0.0010346047347411513\n",
            "MAVG Model -> Epoch: 5900 | Loss: 7.905002712504938e-05\n",
            "MI Model -> Epoch: 5900 | Loss: 0.0037878078874200583\n",
            "ADX Model -> Epoch: 5900 | Loss: 0.0002888328453991562\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import random, os\n",
        "import pandas as pd\n",
        "import torch\n",
        "total_files = 30 * 200\n",
        "\n",
        "for a_file in range(total_files):\n",
        "    # pick a random file from dir\n",
        "    file = random.choice(os.listdir(\"./stocks_data\"))\n",
        "    if file.endswith(\".csv\"):\n",
        "        # read csv file\n",
        "        df = pd.read_csv(\"./stocks_data/\" + file)\n",
        "        fundamental_x, fundamental_y, mavg_x, mavg_y, mi_x, mi_y, adx_x, adx_y = data_fragmenter(df=df, device=device)\n",
        "\n",
        "        ## training loop\n",
        "        epoch = True\n",
        "        # used while loop just to pretend as training loop\n",
        "        while epoch:\n",
        "            ## forward pass\n",
        "            y_fundamental_pred = model_fundamental(fundamental_x)\n",
        "            y_mavg_pred = model_mavg(mavg_x)\n",
        "            y_mi_pred = model_mi(mi_x)\n",
        "            y_adx_pred = model_adx(adx_x)\n",
        "\n",
        "            ## calculate the loss\n",
        "            loss_fundamental = fundamental_loss_fn(y_fundamental_pred, fundamental_y)\n",
        "            loss_mavg = mavg_loss_fn(y_mavg_pred, mavg_y)\n",
        "            loss_mi = mi_loss_fn(y_mi_pred, mi_y)\n",
        "            loss_adx = adx_loss_fn(y_adx_pred, adx_y)\n",
        "\n",
        "            ## optimizer sero grad\n",
        "            optimizer_fundamental.zero_grad()\n",
        "            optimizer_mavg.zero_grad()\n",
        "            optimizer_mi.zero_grad()\n",
        "            optimizer_adx.zero_grad()\n",
        "\n",
        "            ## loss backward (backpropagation)\n",
        "            loss_fundamental.backward()\n",
        "            loss_mavg.backward()\n",
        "            loss_mi.backward()\n",
        "            loss_adx.backward()\n",
        "\n",
        "            ## optimzer step (gradient descent)\n",
        "            optimizer_fundamental.step()\n",
        "            optimizer_mavg.step()\n",
        "            optimizer_mi.step()\n",
        "            optimizer_adx.step()\n",
        "\n",
        "            epoch = False\n",
        "\n",
        "        if a_file % 100 == 0:\n",
        "            print(f\"Fundamental Model -> Epoch: {a_file} | Loss: {loss_fundamental}\")\n",
        "            print(f\"MAVG Model -> Epoch: {a_file} | Loss: {loss_mavg}\")\n",
        "            print(f\"MI Model -> Epoch: {a_file} | Loss: {loss_mi}\")\n",
        "            print(f\"ADX Model -> Epoch: {a_file} | Loss: {loss_adx}\")\n",
        "            print()\n",
        "\n",
        "\n",
        "## IT WORKS, RUN THIS IN COLAB TO MAKE TRAINING FASTER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "WrlQqDzbU442"
      },
      "outputs": [],
      "source": [
        "PATH = \"/content/models\"\n",
        "\n",
        "# Save each model's state dictionary to a separate file\n",
        "torch.save(model_fundamental.state_dict(), f=os.path.join(PATH, \"model_fundamental.pth\"))\n",
        "torch.save(model_mavg.state_dict(), os.path.join(PATH, \"model_mavg.pth\"))\n",
        "torch.save(model_mi.state_dict(), os.path.join(PATH, \"model_mi.pth\"))\n",
        "torch.save(model_adx.state_dict(), os.path.join(PATH, \"model_adx.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E1P-1JvmINi",
        "outputId": "878c1425-540b-46bf-9376-47a8f6dbfae5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: models/ (stored 0%)\n",
            "  adding: models/model_adx.pth (deflated 8%)\n",
            "  adding: models/model_mavg.pth (deflated 8%)\n",
            "  adding: models/model_fundamental.pth (deflated 8%)\n",
            "  adding: models/model_mi.pth (deflated 8%)\n"
          ]
        }
      ],
      "source": [
        "# !zip -r models.zip \"./models\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUq84sH3omHM"
      },
      "source": [
        "### **Building Trading Env** (from scratch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plan:\n",
        "1. Make Env for trading\n",
        "2. Add LSTM predictions function and add predictions to observation space\n",
        "3. Also, add a function to calculate metrics: Sharpe Ratio and Sorinto Ratio\n",
        "4. In training enable `tensorboard logits`\n",
        "5. Use PyPlot (better than matplotlib)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch    # for loading LSTM models\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3 import PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class LSTMv1(nn.Module):\n",
        "    def __init__(self, input_features, hidden_features, num_layers, output_features, device=\"cpu\"):\n",
        "        super().__init__()\n",
        "        self.hidden_features = hidden_features\n",
        "        self.num_layers = num_layers\n",
        "        self.device = device\n",
        "\n",
        "        self.lstm = nn.LSTM(input_features, hidden_features, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_features, output_features)\n",
        "        self.to(device=device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_features, device=self.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_features, device=self.device)\n",
        "\n",
        "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out)\n",
        "        return out[:, -1, :]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## hyper parameters\n",
        "MAX_ACCOUNT_BALANCE = 2147483647\n",
        "MAX_NUM_SHARES = 2147483647\n",
        "MAX_SHARE_PRICE = 5000\n",
        "MAX_STEPS = 20000\n",
        "INITIAL_ACCOUNT_BALANCE = 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class StockTradingEnv(gym.Env):\n",
        "    def __init__(self, df):\n",
        "        super().__init__()\n",
        "\n",
        "        # set dataframe and reward range\n",
        "        self.df = df\n",
        "        self.reward_range = (0, MAX_ACCOUNT_BALANCE)\n",
        "\n",
        "        # set continuous action space\n",
        "        self.action_space = spaces.Box(low=np.array([0, 0]), high=np.array([3, 1]), dtype=np.float32)\n",
        "\n",
        "        # set observation space\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(15, 6), dtype=np.float32)\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        # performs action\n",
        "        self._take_action(action)\n",
        "        self.current_step += 1\n",
        "\n",
        "        if self.current_step > len(self.df.loc[:, \"Open\"].values) - 6:\n",
        "            self.current_step = 0\n",
        "\n",
        "        delay_modifier = (self.current_step / MAX_STEPS)\n",
        "\n",
        "        reward = self.balance * delay_modifier\n",
        "        self.rewards.append(reward)  # add reward to rewards list for ratio calculation\n",
        "        done = self.net_worth <= 0\n",
        "\n",
        "        obs = self._next_observation()\n",
        "\n",
        "        return obs, reward, done, {}\n",
        "\n",
        "\n",
        "    def _take_action(self, action):\n",
        "        current_price = random.uniform(self.df.loc[self.current_step, \"Open\"], self.df.loc[self.current_step, \"Close\"])\n",
        "\n",
        "        action_type = action[0]\n",
        "        amount = action[1]\n",
        "\n",
        "        if action_type < 1:\n",
        "            # buy\n",
        "            total_possible = int(self.balance / current_price)\n",
        "            shares_bought = int(total_possible * amount)\n",
        "            prev_cost = self.cost_basis * self.shares_held\n",
        "            additional_cost = shares_bought * current_price\n",
        "\n",
        "            self.balance -= additional_cost\n",
        "            self.cost_basis = (prev_cost + additional_cost) / (self.shares_held + shares_bought)\n",
        "            self.shares_held += shares_bought\n",
        "\n",
        "        elif action_type < 2:\n",
        "            # sell\n",
        "            shares_sold = int(self.shares_held * amount)\n",
        "            self.balance += shares_sold * current_price\n",
        "            self.total_shares_sold += shares_sold\n",
        "            self.total_sales_value += shares_sold * current_price\n",
        "\n",
        "        self.net_worth = self.balance + self.shares_held * current_price\n",
        "\n",
        "        if self.net_worth > self.max_net_worth:\n",
        "            self.max_net_worth = self.net_worth\n",
        "\n",
        "        if self.shares_held == 0:\n",
        "            self.cost_basis = 0\n",
        "\n",
        "\n",
        "    def _next_observation(self):\n",
        "        # get all metrics as obs\n",
        "        frame = np.array([\n",
        "            self.df.loc[self.current_step - 6: self.current_step - 1, 'Open'].values / MAX_SHARE_PRICE,\n",
        "            self.df.loc[self.current_step - 6: self.current_step - 1, 'High'].values / MAX_SHARE_PRICE,\n",
        "            self.df.loc[self.current_step - 6: self.current_step - 1, 'Low'].values / MAX_SHARE_PRICE,\n",
        "            self.df.loc[self.current_step - 6: self.current_step - 1, 'Close'].values / MAX_SHARE_PRICE,\n",
        "            self.df.loc[self.current_step - 6: self.current_step - 1, 'Volume'].values / MAX_NUM_SHARES,\n",
        "            self.df.loc[self.current_step - 6: self.current_step - 1, 'EMA_12'].values / MAX_SHARE_PRICE,\n",
        "            self.df.loc[self.current_step - 6: self.current_step - 1, 'EMA_26'].values / MAX_SHARE_PRICE,\n",
        "            self.df.loc[self.current_step - 6: self.current_step - 1, 'MACD'].values / 100,\n",
        "            self.df.loc[self.current_step - 6: self.current_step - 1, 'Signal'].values / 100,\n",
        "            self.df.loc[self.current_step - 6: self.current_step - 1, 'RSI'].values / 100,\n",
        "            self.df.loc[self.current_step - 6: self.current_step - 1, 'CCI'].values / 200,\n",
        "            self.df.loc[self.current_step - 6: self.current_step - 1, 'ADX'].values / 100,\n",
        "            self.df.loc[self.current_step - 6: self.current_step - 1, 'Sentiment Average'].values / 1,\n",
        "        ])\n",
        "\n",
        "        obs1 = np.append(frame, [[\n",
        "            self.balance / MAX_ACCOUNT_BALANCE,\n",
        "            self.max_net_worth / MAX_ACCOUNT_BALANCE,\n",
        "            self.shares_held / MAX_NUM_SHARES,\n",
        "            self.cost_basis / MAX_SHARE_PRICE,\n",
        "            self.total_shares_sold / MAX_NUM_SHARES,\n",
        "            self.total_sales_value / (MAX_NUM_SHARES * MAX_SHARE_PRICE),\n",
        "        ]], axis=0)\n",
        "\n",
        "        fundamental_predictions, mavg_predictions, mi_predictions, adx_predictions = self._lstm_predictions(self.df)\n",
        "        ## append predicted data to obs\n",
        "        obs2 = np.append(obs1, [[\n",
        "            fundamental_predictions, mavg_predictions, mi_predictions, adx_predictions\n",
        "        ]], axis=0)\n",
        "\n",
        "        obs = obs2\n",
        "        return obs\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        # reset all parameters\n",
        "        self.balance = INITIAL_ACCOUNT_BALANCE\n",
        "        self.net_worth = INITIAL_ACCOUNT_BALANCE\n",
        "        self.max_net_worth = INITIAL_ACCOUNT_BALANCE\n",
        "        self.shares_held = 0\n",
        "        self.cost_basis = 0\n",
        "        self.total_shares_sold = 0\n",
        "        self.total_sales_value = 0\n",
        "        self.rewards = []\n",
        "\n",
        "        # set random current step\n",
        "        self.current_step = random.randint(0, len(self.df.loc[:, \"Open\"].values) - 6)\n",
        "\n",
        "        return self._next_observation()\n",
        "\n",
        "\n",
        "    def calculate_sharpe_ratio(self):\n",
        "        rewards = self.rewards\n",
        "        expected_return = np.mean(rewards)\n",
        "        std_dev = np.std(rewards)\n",
        "        sharpe_ratio = (expected_return - self.risk_free_rate) / std_dev\n",
        "        return sharpe_ratio\n",
        "\n",
        "\n",
        "    def calculate_sorinto_ratio(self):\n",
        "        rewards = self.rewards\n",
        "        expected_return = np.mean(rewards)\n",
        "        downside_returns = [reward for reward in rewards if reward < 0]\n",
        "        downside_std_dev = np.std(downside_returns)\n",
        "        sorinto_ratio = (expected_return - self.risk_free_rate) / downside_std_dev\n",
        "        return sorinto_ratio\n",
        "\n",
        "\n",
        "    def _lstm_predictions(self):\n",
        "        fundamental_data = self.df.loc[self.current_step, ['Open', 'High', 'Low', 'Close', 'Volume']].values\n",
        "        mavg_data = self.df.loc[self.current_step, ['EMA-12', 'EMA_26']].values\n",
        "        mi_data = self.df.loc[self.current_step, ['MACD', 'Signal', 'RSI', 'CCI']].values\n",
        "        adx_data = self.df.loc[self.current_step, ['ADX']].values\n",
        "\n",
        "        fundamental_data = torch.tensor(fundamental_data, dtype=torch.float32, device=device)\n",
        "        mavg_data = torch.tensor(mavg_data, dtype=torch.float32, device=device)\n",
        "        mi_data = torch.tensor(mi_data, dtype=torch.float32, device=device)\n",
        "        adx_data = torch.tensor(adx_data, dtype=torch.float32, device=device)\n",
        "\n",
        "        fundamental_predictions = model_fundamental(fundamental_data)\n",
        "        mavg_predictions = model_mavg(mavg_data)\n",
        "        mi_predictions = model_mi(mi_data)\n",
        "        adx_predictions= model_adx(adx_data)\n",
        "\n",
        "        return fundamental_predictions.numpy(), mavg_predictions.numpy(), mi_predictions.numpy(), adx_predictions.numpy()\n",
        "\n",
        "\n",
        "    def render(self, mode=\"human\", close=False):\n",
        "        # render output\n",
        "        profit = self.net_worth - INITIAL_ACCOUNT_BALANCE\n",
        "\n",
        "        print(f'Step: {self.current_step}')\n",
        "        print(f'Balance: {self.balance}')\n",
        "        print(f'Shares held: {self.shares_held} (Total sold: {self.total_shares_sold})')\n",
        "        print(f'Avg cost for held shares: {self.cost_basis} (Total sales value: {self.total_sales_value})')\n",
        "        print(f'Net worth: {self.net_worth} (Max net worth: {self.max_net_worth})')\n",
        "        print(f'Profit: {profit}')\n",
        "\n",
        "\n",
        "## update code as it takes inputs from LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"./stocks_data/AAPL_data.csv\")\n",
        "fundamental_x, fundamental_y, mavg_x, mavg_y, mi_x, mi_y, adx_x, adx_y = data_fragmenter(df=df, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_fundamental = LSTMv1(len(fundamental_x[0, 0, :]), hidden_features=128, num_layers=3, output_features=len(fundamental_y[0, :]), device=device)\n",
        "model_mavg = LSTMv1(len(mavg_x[0, 0, :]), hidden_features=128, num_layers=3, output_features=len(mavg_y[0, :]), device=device)\n",
        "model_mi = LSTMv1(len(mi_x[0, 0, :]), hidden_features=128, num_layers=3, output_features=len(mi_y[0, :]), device=device)\n",
        "model_adx = LSTMv1(len(adx_x[0, 0, :]), hidden_features=128, num_layers=3, output_features=len(adx_y[0, :]), device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## load saved models\n",
        "model_fundamental.load_state_dict(torch.load(\"./models/model_fundamental.pth\"))\n",
        "model_mavg.load_state_dict(torch.load(\"./models/model_mavg.pth\"))\n",
        "model_mi.load_state_dict(torch.load(\"./models/model_mi.pth\"))\n",
        "model_adx.load_state_dict(torch.load(\"./models/model_adx.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = DummyVecEnv([lambda: StockTradingEnv(df=df)])\n",
        "\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
        "model.learn(total_timesteps=100)\n",
        "## change this for training"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "RL_project",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
