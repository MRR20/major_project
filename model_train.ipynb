{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fq6ELSWbU44i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsyyT-zhU44k",
        "outputId": "41ca4619-f263-439a-9154-2dc7d30b729c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>EMA_12</th>\n",
              "      <th>EMA_26</th>\n",
              "      <th>MACD</th>\n",
              "      <th>Signal</th>\n",
              "      <th>RSI</th>\n",
              "      <th>CCI</th>\n",
              "      <th>ADX</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-03-02 00:00:00-05:00</td>\n",
              "      <td>28.865108</td>\n",
              "      <td>29.095135</td>\n",
              "      <td>28.652947</td>\n",
              "      <td>28.829374</td>\n",
              "      <td>192386800</td>\n",
              "      <td>28.829374</td>\n",
              "      <td>28.829374</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>45.526105</td>\n",
              "      <td>56.240216</td>\n",
              "      <td>28.673114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-03-03 00:00:00-05:00</td>\n",
              "      <td>28.800338</td>\n",
              "      <td>28.925401</td>\n",
              "      <td>28.606040</td>\n",
              "      <td>28.889668</td>\n",
              "      <td>151265200</td>\n",
              "      <td>28.838650</td>\n",
              "      <td>28.833840</td>\n",
              "      <td>0.004810</td>\n",
              "      <td>0.000962</td>\n",
              "      <td>45.526105</td>\n",
              "      <td>56.240216</td>\n",
              "      <td>28.673114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-03-04 00:00:00-05:00</td>\n",
              "      <td>28.831606</td>\n",
              "      <td>28.934334</td>\n",
              "      <td>28.657410</td>\n",
              "      <td>28.706539</td>\n",
              "      <td>126665200</td>\n",
              "      <td>28.818325</td>\n",
              "      <td>28.824411</td>\n",
              "      <td>-0.006085</td>\n",
              "      <td>-0.000448</td>\n",
              "      <td>45.526105</td>\n",
              "      <td>56.240216</td>\n",
              "      <td>28.673114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-03-05 00:00:00-05:00</td>\n",
              "      <td>28.715477</td>\n",
              "      <td>28.753442</td>\n",
              "      <td>28.085693</td>\n",
              "      <td>28.230856</td>\n",
              "      <td>226068400</td>\n",
              "      <td>28.727945</td>\n",
              "      <td>28.780444</td>\n",
              "      <td>-0.052498</td>\n",
              "      <td>-0.010858</td>\n",
              "      <td>45.526105</td>\n",
              "      <td>56.240216</td>\n",
              "      <td>28.673114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-03-06 00:00:00-05:00</td>\n",
              "      <td>28.675274</td>\n",
              "      <td>28.891902</td>\n",
              "      <td>28.197354</td>\n",
              "      <td>28.273285</td>\n",
              "      <td>291368400</td>\n",
              "      <td>28.657998</td>\n",
              "      <td>28.742876</td>\n",
              "      <td>-0.084879</td>\n",
              "      <td>-0.025662</td>\n",
              "      <td>45.526105</td>\n",
              "      <td>56.240216</td>\n",
              "      <td>28.673114</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Date       Open       High        Low      Close  \\\n",
              "0  2015-03-02 00:00:00-05:00  28.865108  29.095135  28.652947  28.829374   \n",
              "1  2015-03-03 00:00:00-05:00  28.800338  28.925401  28.606040  28.889668   \n",
              "2  2015-03-04 00:00:00-05:00  28.831606  28.934334  28.657410  28.706539   \n",
              "3  2015-03-05 00:00:00-05:00  28.715477  28.753442  28.085693  28.230856   \n",
              "4  2015-03-06 00:00:00-05:00  28.675274  28.891902  28.197354  28.273285   \n",
              "\n",
              "      Volume     EMA_12     EMA_26      MACD    Signal        RSI        CCI  \\\n",
              "0  192386800  28.829374  28.829374  0.000000  0.000000  45.526105  56.240216   \n",
              "1  151265200  28.838650  28.833840  0.004810  0.000962  45.526105  56.240216   \n",
              "2  126665200  28.818325  28.824411 -0.006085 -0.000448  45.526105  56.240216   \n",
              "3  226068400  28.727945  28.780444 -0.052498 -0.010858  45.526105  56.240216   \n",
              "4  291368400  28.657998  28.742876 -0.084879 -0.025662  45.526105  56.240216   \n",
              "\n",
              "         ADX  \n",
              "0  28.673114  \n",
              "1  28.673114  \n",
              "2  28.673114  \n",
              "3  28.673114  \n",
              "4  28.673114  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"./stocks_data/AAPL_data.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nq_D-i70U44n",
        "outputId": "57f34236-c429-4b42-ea5a-dde7c4bb1118"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2515, (2515, 13))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data), data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFUtKeWJU44n",
        "outputId": "f9704bdb-d854-4500-c8d0-ba9227b8b37e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'EMA_12', 'EMA_26',\n",
              "       'MACD', 'Signal', 'RSI', 'CCI', 'ADX'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJl7epEyU44o"
      },
      "outputs": [],
      "source": [
        "data = data.set_index(\"Date\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BTVZcL8U44o",
        "outputId": "33e69c3b-b9e8-49ce-f9d0-43255c070462"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>EMA_12</th>\n",
              "      <th>EMA_26</th>\n",
              "      <th>MACD</th>\n",
              "      <th>Signal</th>\n",
              "      <th>RSI</th>\n",
              "      <th>CCI</th>\n",
              "      <th>ADX</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2025-02-21 00:00:00-05:00</th>\n",
              "      <td>245.949997</td>\n",
              "      <td>248.690002</td>\n",
              "      <td>245.220001</td>\n",
              "      <td>245.550003</td>\n",
              "      <td>53197400</td>\n",
              "      <td>240.208448</td>\n",
              "      <td>237.920002</td>\n",
              "      <td>2.288446</td>\n",
              "      <td>0.363129</td>\n",
              "      <td>62.766179</td>\n",
              "      <td>103.163767</td>\n",
              "      <td>31.180457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-02-24 00:00:00-05:00</th>\n",
              "      <td>244.929993</td>\n",
              "      <td>248.860001</td>\n",
              "      <td>244.419998</td>\n",
              "      <td>247.100006</td>\n",
              "      <td>51326400</td>\n",
              "      <td>241.268688</td>\n",
              "      <td>238.600002</td>\n",
              "      <td>2.668686</td>\n",
              "      <td>0.824240</td>\n",
              "      <td>80.231290</td>\n",
              "      <td>90.587796</td>\n",
              "      <td>28.337470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-02-25 00:00:00-05:00</th>\n",
              "      <td>248.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>244.910004</td>\n",
              "      <td>247.039993</td>\n",
              "      <td>48013300</td>\n",
              "      <td>242.156581</td>\n",
              "      <td>239.225187</td>\n",
              "      <td>2.931394</td>\n",
              "      <td>1.245671</td>\n",
              "      <td>76.585168</td>\n",
              "      <td>83.906297</td>\n",
              "      <td>24.582475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-02-26 00:00:00-05:00</th>\n",
              "      <td>244.330002</td>\n",
              "      <td>244.979996</td>\n",
              "      <td>239.130005</td>\n",
              "      <td>240.360001</td>\n",
              "      <td>44433600</td>\n",
              "      <td>241.880184</td>\n",
              "      <td>239.309247</td>\n",
              "      <td>2.570937</td>\n",
              "      <td>1.510724</td>\n",
              "      <td>62.116289</td>\n",
              "      <td>19.244203</td>\n",
              "      <td>21.212065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-02-27 00:00:00-05:00</th>\n",
              "      <td>239.410004</td>\n",
              "      <td>242.460007</td>\n",
              "      <td>237.059998</td>\n",
              "      <td>237.300003</td>\n",
              "      <td>41078200</td>\n",
              "      <td>241.175541</td>\n",
              "      <td>239.160414</td>\n",
              "      <td>2.015127</td>\n",
              "      <td>1.611605</td>\n",
              "      <td>56.035173</td>\n",
              "      <td>-15.982410</td>\n",
              "      <td>18.992802</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 Open        High         Low       Close  \\\n",
              "Date                                                                        \n",
              "2025-02-21 00:00:00-05:00  245.949997  248.690002  245.220001  245.550003   \n",
              "2025-02-24 00:00:00-05:00  244.929993  248.860001  244.419998  247.100006   \n",
              "2025-02-25 00:00:00-05:00  248.000000  250.000000  244.910004  247.039993   \n",
              "2025-02-26 00:00:00-05:00  244.330002  244.979996  239.130005  240.360001   \n",
              "2025-02-27 00:00:00-05:00  239.410004  242.460007  237.059998  237.300003   \n",
              "\n",
              "                             Volume      EMA_12      EMA_26      MACD  \\\n",
              "Date                                                                    \n",
              "2025-02-21 00:00:00-05:00  53197400  240.208448  237.920002  2.288446   \n",
              "2025-02-24 00:00:00-05:00  51326400  241.268688  238.600002  2.668686   \n",
              "2025-02-25 00:00:00-05:00  48013300  242.156581  239.225187  2.931394   \n",
              "2025-02-26 00:00:00-05:00  44433600  241.880184  239.309247  2.570937   \n",
              "2025-02-27 00:00:00-05:00  41078200  241.175541  239.160414  2.015127   \n",
              "\n",
              "                             Signal        RSI         CCI        ADX  \n",
              "Date                                                                   \n",
              "2025-02-21 00:00:00-05:00  0.363129  62.766179  103.163767  31.180457  \n",
              "2025-02-24 00:00:00-05:00  0.824240  80.231290   90.587796  28.337470  \n",
              "2025-02-25 00:00:00-05:00  1.245671  76.585168   83.906297  24.582475  \n",
              "2025-02-26 00:00:00-05:00  1.510724  62.116289   19.244203  21.212065  \n",
              "2025-02-27 00:00:00-05:00  1.611605  56.035173  -15.982410  18.992802  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvB09lelU44p",
        "outputId": "98463854-cb4f-48f0-da4b-97e558995ada"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.03484219, 0.03398254, 0.03452298, 0.03425526, 0.2703879 ,\n",
              "       0.03184143, 0.03052919, 0.42180037, 0.40620287, 0.45542002,\n",
              "       0.59169241, 0.3071847 ])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# normalizing data\n",
        "data = data.values\n",
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "data_scaled[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0AaAVZoU44p",
        "outputId": "c70befff-9878-48a8-95d4-6df2fa727c7e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\conda_tmp\\ipykernel_1912\\1879639991.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
            "  x = torch.tensor(xs).type(torch.float32)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor([[0.0348, 0.0340, 0.0345, 0.0343, 0.2704, 0.0318, 0.0305, 0.4218, 0.4062,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0346, 0.0333, 0.0343, 0.0345, 0.2047, 0.0319, 0.0305, 0.4221, 0.4063,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0347, 0.0333, 0.0345, 0.0337, 0.1653, 0.0318, 0.0305, 0.4214, 0.4062,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0342, 0.0326, 0.0321, 0.0317, 0.3242, 0.0314, 0.0303, 0.4184, 0.4054,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0340, 0.0331, 0.0326, 0.0319, 0.4286, 0.0311, 0.0301, 0.4163, 0.4044,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0336, 0.0333, 0.0315, 0.0324, 0.5289, 0.0309, 0.0300, 0.4153, 0.4033,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0322, 0.0311, 0.0303, 0.0300, 0.4031, 0.0304, 0.0297, 0.4116, 0.4016,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0306, 0.0288, 0.0287, 0.0278, 0.4037, 0.0296, 0.0293, 0.4062, 0.3991,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0283, 0.0290, 0.0282, 0.0299, 0.2721, 0.0292, 0.0290, 0.4047, 0.3967,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0303, 0.0294, 0.0291, 0.0291, 0.2942, 0.0288, 0.0287, 0.4027, 0.3944,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0298, 0.0290, 0.0294, 0.0304, 0.1922, 0.0287, 0.0286, 0.4030, 0.3926,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0317, 0.0312, 0.0320, 0.0323, 0.2891, 0.0289, 0.0286, 0.4058, 0.3918,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0327, 0.0329, 0.0327, 0.0337, 0.3802, 0.0292, 0.0287, 0.4098, 0.3920,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0344, 0.0330, 0.0337, 0.0328, 0.2558, 0.0294, 0.0287, 0.4120, 0.3927,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0339, 0.0322, 0.0316, 0.0313, 0.4021, 0.0293, 0.0286, 0.4120, 0.3932,\n",
              "          0.4150, 0.5206, 0.3072],\n",
              "         [0.0328, 0.0317, 0.0328, 0.0325, 0.2040, 0.0294, 0.0286, 0.4136, 0.3940,\n",
              "          0.4469, 0.5714, 0.3072],\n",
              "         [0.0329, 0.0319, 0.0329, 0.0320, 0.1729, 0.0294, 0.0286, 0.4143, 0.3948,\n",
              "          0.4541, 0.5765, 0.3072],\n",
              "         [0.0323, 0.0307, 0.0299, 0.0289, 0.2931, 0.0289, 0.0283, 0.4112, 0.3947,\n",
              "          0.4270, 0.4279, 0.3072],\n",
              "         [0.0287, 0.0289, 0.0291, 0.0297, 0.2670, 0.0287, 0.0281, 0.4098, 0.3944,\n",
              "          0.4457, 0.4078, 0.3072],\n",
              "         [0.0304, 0.0288, 0.0294, 0.0288, 0.2157, 0.0283, 0.0278, 0.4077, 0.3936,\n",
              "          0.4102, 0.4058, 0.3072],\n",
              "         [0.0299, 0.0304, 0.0305, 0.0317, 0.2640, 0.0284, 0.0278, 0.4099, 0.3935,\n",
              "          0.5472, 0.5216, 0.3072],\n",
              "         [0.0319, 0.0304, 0.0308, 0.0299, 0.2320, 0.0283, 0.0277, 0.4095, 0.3933,\n",
              "          0.5557, 0.4802, 0.3072],\n",
              "         [0.0307, 0.0292, 0.0296, 0.0297, 0.2226, 0.0281, 0.0276, 0.4091, 0.3931,\n",
              "          0.4983, 0.4140, 0.3072],\n",
              "         [0.0309, 0.0296, 0.0306, 0.0307, 0.1689, 0.0281, 0.0275, 0.4101, 0.3931,\n",
              "          0.5484, 0.4644, 0.3072],\n",
              "         [0.0303, 0.0314, 0.0308, 0.0326, 0.2007, 0.0284, 0.0276, 0.4134, 0.3939,\n",
              "          0.5638, 0.5526, 0.3072],\n",
              "         [0.0333, 0.0320, 0.0323, 0.0314, 0.1867, 0.0285, 0.0276, 0.4146, 0.3948,\n",
              "          0.4767, 0.5749, 0.3072],\n",
              "         [0.0316, 0.0304, 0.0314, 0.0310, 0.2015, 0.0285, 0.0275, 0.4151, 0.3956,\n",
              "          0.4250, 0.5099, 0.3072],\n",
              "         [0.0316, 0.0305, 0.0311, 0.0319, 0.1706, 0.0286, 0.0276, 0.4167, 0.3966,\n",
              "          0.4778, 0.5511, 0.3072],\n",
              "         [0.0317, 0.0311, 0.0317, 0.0324, 0.2198, 0.0288, 0.0277, 0.4186, 0.3978,\n",
              "          0.5383, 0.6079, 0.2795],\n",
              "         [0.0340, 0.0324, 0.0329, 0.0322, 0.1954, 0.0290, 0.0277, 0.4198, 0.3990,\n",
              "          0.4925, 0.6847, 0.2672]]),\n",
              " tensor([0.0327, 0.0312, 0.0323, 0.0316, 0.1261, 0.0290, 0.0277, 0.4202, 0.4001,\n",
              "         0.4916, 0.6115, 0.2574]))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# preparing dataset for LSTM\n",
        "\n",
        "sequence_len = 30   #considering 30 days window\n",
        "xs = []\n",
        "ys = []\n",
        "\n",
        "for i in range(len(data_scaled) - sequence_len):\n",
        "    xs.append(data_scaled[i:i+sequence_len])\n",
        "    ys.append(data_scaled[i+sequence_len])\n",
        "\n",
        "x = torch.tensor(xs).type(torch.float32)\n",
        "y = torch.tensor(ys).type(torch.float32)\n",
        "x[0], y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lvfBcLvU44q",
        "outputId": "3885a2a8-e26b-4d71-e78c-305ec4a542e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([2485, 30, 12]), torch.Size([2485, 12]))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZBcnzjUU44r",
        "outputId": "39cd1fae-7dd8-43c7-ef17-09ad6b8bb47d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1988\n",
            "torch.Size([1988, 30, 12]) torch.Size([497, 30, 12]) torch.Size([1988, 12]) torch.Size([497, 12])\n"
          ]
        }
      ],
      "source": [
        "# dividing data into train and test set\n",
        "split_ratio = 0.8\n",
        "split_size = int(len(x) * split_ratio)\n",
        "print(split_size)\n",
        "\n",
        "X_train = x[:split_size]\n",
        "X_test = x[split_size:]\n",
        "y_train = y[:split_size]\n",
        "y_test = y[split_size:]\n",
        "\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqLg8pBHU44s",
        "outputId": "39a8e675-f145-454e-b600-2d075fa21697"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.0348, 0.0340, 0.0345, 0.0343, 0.2704, 0.0318, 0.0305, 0.4218, 0.4062,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0346, 0.0333, 0.0343, 0.0345, 0.2047, 0.0319, 0.0305, 0.4221, 0.4063,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0347, 0.0333, 0.0345, 0.0337, 0.1653, 0.0318, 0.0305, 0.4214, 0.4062,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0342, 0.0326, 0.0321, 0.0317, 0.3242, 0.0314, 0.0303, 0.4184, 0.4054,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0340, 0.0331, 0.0326, 0.0319, 0.4286, 0.0311, 0.0301, 0.4163, 0.4044,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0336, 0.0333, 0.0315, 0.0324, 0.5289, 0.0309, 0.0300, 0.4153, 0.4033,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0322, 0.0311, 0.0303, 0.0300, 0.4031, 0.0304, 0.0297, 0.4116, 0.4016,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0306, 0.0288, 0.0287, 0.0278, 0.4037, 0.0296, 0.0293, 0.4062, 0.3991,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0283, 0.0290, 0.0282, 0.0299, 0.2721, 0.0292, 0.0290, 0.4047, 0.3967,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0303, 0.0294, 0.0291, 0.0291, 0.2942, 0.0288, 0.0287, 0.4027, 0.3944,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0298, 0.0290, 0.0294, 0.0304, 0.1922, 0.0287, 0.0286, 0.4030, 0.3926,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0317, 0.0312, 0.0320, 0.0323, 0.2891, 0.0289, 0.0286, 0.4058, 0.3918,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0327, 0.0329, 0.0327, 0.0337, 0.3802, 0.0292, 0.0287, 0.4098, 0.3920,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0344, 0.0330, 0.0337, 0.0328, 0.2558, 0.0294, 0.0287, 0.4120, 0.3927,\n",
              "          0.4554, 0.5917, 0.3072],\n",
              "         [0.0339, 0.0322, 0.0316, 0.0313, 0.4021, 0.0293, 0.0286, 0.4120, 0.3932,\n",
              "          0.4150, 0.5206, 0.3072],\n",
              "         [0.0328, 0.0317, 0.0328, 0.0325, 0.2040, 0.0294, 0.0286, 0.4136, 0.3940,\n",
              "          0.4469, 0.5714, 0.3072],\n",
              "         [0.0329, 0.0319, 0.0329, 0.0320, 0.1729, 0.0294, 0.0286, 0.4143, 0.3948,\n",
              "          0.4541, 0.5765, 0.3072],\n",
              "         [0.0323, 0.0307, 0.0299, 0.0289, 0.2931, 0.0289, 0.0283, 0.4112, 0.3947,\n",
              "          0.4270, 0.4279, 0.3072],\n",
              "         [0.0287, 0.0289, 0.0291, 0.0297, 0.2670, 0.0287, 0.0281, 0.4098, 0.3944,\n",
              "          0.4457, 0.4078, 0.3072],\n",
              "         [0.0304, 0.0288, 0.0294, 0.0288, 0.2157, 0.0283, 0.0278, 0.4077, 0.3936,\n",
              "          0.4102, 0.4058, 0.3072],\n",
              "         [0.0299, 0.0304, 0.0305, 0.0317, 0.2640, 0.0284, 0.0278, 0.4099, 0.3935,\n",
              "          0.5472, 0.5216, 0.3072],\n",
              "         [0.0319, 0.0304, 0.0308, 0.0299, 0.2320, 0.0283, 0.0277, 0.4095, 0.3933,\n",
              "          0.5557, 0.4802, 0.3072],\n",
              "         [0.0307, 0.0292, 0.0296, 0.0297, 0.2226, 0.0281, 0.0276, 0.4091, 0.3931,\n",
              "          0.4983, 0.4140, 0.3072],\n",
              "         [0.0309, 0.0296, 0.0306, 0.0307, 0.1689, 0.0281, 0.0275, 0.4101, 0.3931,\n",
              "          0.5484, 0.4644, 0.3072],\n",
              "         [0.0303, 0.0314, 0.0308, 0.0326, 0.2007, 0.0284, 0.0276, 0.4134, 0.3939,\n",
              "          0.5638, 0.5526, 0.3072],\n",
              "         [0.0333, 0.0320, 0.0323, 0.0314, 0.1867, 0.0285, 0.0276, 0.4146, 0.3948,\n",
              "          0.4767, 0.5749, 0.3072],\n",
              "         [0.0316, 0.0304, 0.0314, 0.0310, 0.2015, 0.0285, 0.0275, 0.4151, 0.3956,\n",
              "          0.4250, 0.5099, 0.3072],\n",
              "         [0.0316, 0.0305, 0.0311, 0.0319, 0.1706, 0.0286, 0.0276, 0.4167, 0.3966,\n",
              "          0.4778, 0.5511, 0.3072],\n",
              "         [0.0317, 0.0311, 0.0317, 0.0324, 0.2198, 0.0288, 0.0277, 0.4186, 0.3978,\n",
              "          0.5383, 0.6079, 0.2795],\n",
              "         [0.0340, 0.0324, 0.0329, 0.0322, 0.1954, 0.0290, 0.0277, 0.4198, 0.3990,\n",
              "          0.4925, 0.6847, 0.2672]]),\n",
              " tensor([0.0327, 0.0312, 0.0323, 0.0316, 0.1261, 0.0290, 0.0277, 0.4202, 0.4001,\n",
              "         0.4916, 0.6115, 0.2574]))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0], y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_bkGVmnU44s"
      },
      "outputs": [],
      "source": [
        "### build LSTM model\n",
        "\n",
        "class LSTMv0(nn.Module):\n",
        "    def __init__(self, input_features, hidden_features, num_layers, output_features):\n",
        "        super().__init__()\n",
        "        self.hidden_features = hidden_features\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_features, hidden_features, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_features, output_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_features)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_features)\n",
        "\n",
        "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out)\n",
        "        return out[:, -1, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REIzbeqnU44t"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "INPUT_FEATURES = len(X_train[0, 0, :])\n",
        "HIDDEN_FEATURES = 30\n",
        "NUM_LAYERS = 3\n",
        "OUTPUT_FEATURES = len(y_train[0, :])\n",
        "\n",
        "model_0 = LSTMv0(INPUT_FEATURES, HIDDEN_FEATURES, NUM_LAYERS, OUTPUT_FEATURES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qS73MlktU44t",
        "outputId": "9332fdfa-b0a5-48f6-a8c6-31eec13e5703"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LSTMv0(\n",
              "  (lstm): LSTM(12, 30, num_layers=3, batch_first=True)\n",
              "  (fc): Linear(in_features=30, out_features=12, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGorOrc_U44u"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgdYA6FDU44u",
        "outputId": "6ea736ac-c9bf-4099-8da1-1d2689e1eba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 | Loss: 0.1438 | Test Loss: 0.3873\n",
            "Epoch: 20 | Loss: 0.1343 | Test Loss: 0.3722\n",
            "Epoch: 40 | Loss: 0.1255 | Test Loss: 0.3583\n",
            "Epoch: 60 | Loss: 0.1176 | Test Loss: 0.3453\n",
            "Epoch: 80 | Loss: 0.1102 | Test Loss: 0.3332\n",
            "Epoch: 100 | Loss: 0.1036 | Test Loss: 0.3219\n",
            "Epoch: 120 | Loss: 0.0974 | Test Loss: 0.3113\n",
            "Epoch: 140 | Loss: 0.0918 | Test Loss: 0.3014\n",
            "Epoch: 160 | Loss: 0.0867 | Test Loss: 0.2922\n",
            "Epoch: 180 | Loss: 0.0819 | Test Loss: 0.2836\n"
          ]
        }
      ],
      "source": [
        "# training loop\n",
        "epochs = 200\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # train mode\n",
        "    model_0.train()\n",
        "\n",
        "    # forward pass\n",
        "    y_pred = model_0(X_train)\n",
        "\n",
        "    # calulate loss\n",
        "    loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "    # optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # backward\n",
        "    loss.backward()\n",
        "\n",
        "    # step optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "    model_0.eval()\n",
        "    with torch.inference_mode():\n",
        "        test_pred = model_0(X_test)\n",
        "        test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "    # print\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"Epoch: {epoch} | Loss: {loss:.4f} | Test Loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymOHi-UfU44v",
        "outputId": "76187b98-7393-4f0a-9aca-944eb987b8a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.1817,  0.0841,  0.0656,  0.0115,  0.0249,  0.1987, -0.0058,  0.1386,\n",
              "          0.2414,  0.3063,  0.2020,  0.0855],\n",
              "        [ 0.1817,  0.0841,  0.0656,  0.0114,  0.0248,  0.1989, -0.0059,  0.1386,\n",
              "          0.2412,  0.3063,  0.2020,  0.0854],\n",
              "        [ 0.1817,  0.0840,  0.0657,  0.0113,  0.0247,  0.1991, -0.0059,  0.1386,\n",
              "          0.2412,  0.3063,  0.2020,  0.0853],\n",
              "        [ 0.1818,  0.0840,  0.0657,  0.0112,  0.0247,  0.1992, -0.0060,  0.1386,\n",
              "          0.2412,  0.3062,  0.2020,  0.0853],\n",
              "        [ 0.1818,  0.0840,  0.0656,  0.0112,  0.0247,  0.1993, -0.0060,  0.1386,\n",
              "          0.2412,  0.3063,  0.2020,  0.0853]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate model with test values\n",
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "    eval_pred = model_0(X_test)\n",
        "eval_pred[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFMgYlqyU44v",
        "outputId": "4bb833c5-5a56-4f7a-f9fc-e78ca271ee8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.1838,  0.0838,  0.0634,  0.0108,  0.0244,  0.2005, -0.0067,  0.1374,\n",
              "          0.2425,  0.3060,  0.2017,  0.0864],\n",
              "        [ 0.1839,  0.0837,  0.0633,  0.0108,  0.0245,  0.2004, -0.0067,  0.1373,\n",
              "          0.2428,  0.3058,  0.2015,  0.0864],\n",
              "        [ 0.1839,  0.0836,  0.0634,  0.0107,  0.0245,  0.2004, -0.0067,  0.1372,\n",
              "          0.2430,  0.3055,  0.2014,  0.0864],\n",
              "        [ 0.1840,  0.0835,  0.0635,  0.0106,  0.0245,  0.2004, -0.0066,  0.1371,\n",
              "          0.2432,  0.3053,  0.2012,  0.0864],\n",
              "        [ 0.1840,  0.0834,  0.0635,  0.0105,  0.0246,  0.2004, -0.0066,  0.1370,\n",
              "          0.2434,  0.3051,  0.2011,  0.0865]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_pred[-5: ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vq9QtGiU44w"
      },
      "source": [
        "### **Start from scratch**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTZTh_jVU44x"
      },
      "source": [
        "**Plan**\n",
        "1. Make LSTM function that can be used to fit different dataframes, and Train in seperately\n",
        "2. Make Stock Trading Env\n",
        "3. Use Stable_Baselines3 to import PPO model, and Trian it with LSTM(that are trained before)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVNygFa4U44x"
      },
      "outputs": [],
      "source": [
        "# ## Make a function that can take data and break-down it into different dataframes (or inputs)\n",
        "\n",
        "# import pandas as pd\n",
        "# import torch\n",
        "# import torch.nn.functional as F\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# def data_fragmenter(df: pd.DataFrame):\n",
        "#     scaler = MinMaxScaler()\n",
        "#     df_fundamental = df[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "#     df_mavg = df[[\"EMA_12\", \"EMA_26\"]]\n",
        "#     df_mi = df[[\"MACD\", \"Signal\", \"RSI\", \"CCI\"]]\n",
        "#     df_adx = df[[\"ADX\"]]\n",
        "\n",
        "#     # normalize\n",
        "#     df_fundamental = scaler.fit_transform(df_fundamental)\n",
        "#     df_mavg = scaler.fit_transform(df_mavg)\n",
        "#     df_mi = scaler.fit_transform(df_mi)\n",
        "#     df_adx = scaler.fit_transform(df_adx)\n",
        "\n",
        "#     return df_fundamental, df_mavg, df_mi, df_adx\n",
        "\n",
        "# df = pd.read_csv(\"./stocks_data/AAPL_data.csv\")\n",
        "# fundamental, mavg, mi, adx = data_fragmenter(df=df)\n",
        "# fundamental[:5], mavg[:5], mi[:5], adx[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq8DfhbmU44y"
      },
      "source": [
        "Break Down data into columns or dataframes\n",
        "1. Open, High, Low, Close, Volume -> Fundamental Data\n",
        "2. EMA_12, EMA_26 -> Moving Avgs\n",
        "3. MACD, Signal, RSI, CCI -> Momentum Indicators\n",
        "4. ADX -> Trend Strength (ADX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5s0mlPnU-UF",
        "outputId": "3e068078-8f2f-41de-e327-d1cf7f35b2b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'major_project'...\n",
            "remote: Enumerating objects: 147, done.\u001b[K\n",
            "remote: Total 147 (delta 0), reused 0 (delta 0), pack-reused 147 (from 1)\u001b[K\n",
            "Receiving objects: 100% (147/147), 29.99 MiB | 11.93 MiB/s, done.\n",
            "Resolving deltas: 100% (69/69), done.\n"
          ]
        }
      ],
      "source": [
        "# !git clone \"https://github.com/MRR20/major_project.git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "b0x-J3OKVjs3"
      },
      "outputs": [],
      "source": [
        "# !cd ./major_project/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gU4-HnUVp0F",
        "outputId": "9f9fdc20-296c-45a4-c235-c618416ef934"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/major_project/stocks_data.zip\n",
            "   creating: /content/stocks_data/\n",
            "   creating: /content/stocks_data/.ipynb_checkpoints/\n",
            "  inflating: /content/stocks_data/.ipynb_checkpoints/AAPL_data-checkpoint.csv  \n",
            "  inflating: /content/stocks_data/.ipynb_checkpoints/AMGN_data-checkpoint.csv  \n",
            "  inflating: /content/stocks_data/AAPL_data.csv  \n",
            "  inflating: /content/stocks_data/AMGN_data.csv  \n",
            "  inflating: /content/stocks_data/AXP_data.csv  \n",
            "  inflating: /content/stocks_data/BA_data.csv  \n",
            "  inflating: /content/stocks_data/CAT_data.csv  \n",
            "  inflating: /content/stocks_data/CRM_data.csv  \n",
            "  inflating: /content/stocks_data/CSCO_data.csv  \n",
            "  inflating: /content/stocks_data/CVX_data.csv  \n",
            "  inflating: /content/stocks_data/DIS_data.csv  \n",
            "  inflating: /content/stocks_data/DOW_data.csv  \n",
            "  inflating: /content/stocks_data/GS_data.csv  \n",
            "  inflating: /content/stocks_data/HD_data.csv  \n",
            "  inflating: /content/stocks_data/HON_data.csv  \n",
            "  inflating: /content/stocks_data/IBM_data.csv  \n",
            "  inflating: /content/stocks_data/INTC_data.csv  \n",
            "  inflating: /content/stocks_data/JNJ_data.csv  \n",
            "  inflating: /content/stocks_data/JPM_data.csv  \n",
            "  inflating: /content/stocks_data/KO_data.csv  \n",
            "  inflating: /content/stocks_data/MCD_data.csv  \n",
            "  inflating: /content/stocks_data/MMM_data.csv  \n",
            "  inflating: /content/stocks_data/MRK_data.csv  \n",
            "  inflating: /content/stocks_data/MSFT_data.csv  \n",
            "  inflating: /content/stocks_data/NKE_data.csv  \n",
            "  inflating: /content/stocks_data/PG_data.csv  \n",
            "  inflating: /content/stocks_data/TRV_data.csv  \n",
            "  inflating: /content/stocks_data/UNH_data.csv  \n",
            "  inflating: /content/stocks_data/VZ_data.csv  \n",
            "  inflating: /content/stocks_data/V_data.csv  \n",
            "  inflating: /content/stocks_data/WBA_data.csv  \n",
            "  inflating: /content/stocks_data/WMT_data.csv  \n"
          ]
        }
      ],
      "source": [
        "# !unzip \"/content/major_project/stocks_data.zip\" -d \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "F0WbnLFVU44y",
        "outputId": "e1cecb4d-6db3-4443-a031-7e1171546086"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Jkr243zYU44z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def data_sequencer(data: torch.Tensor, sequence_len: int, device=\"cpu\"):\n",
        "    xs = []\n",
        "    ys = []\n",
        "\n",
        "    for i in range(len(data) - sequence_len):\n",
        "        xs.append(data[i: i+sequence_len])\n",
        "        ys.append(data[i+sequence_len])\n",
        "\n",
        "    xs = np.array(xs)\n",
        "    ys = np.array(ys)\n",
        "\n",
        "    xs = torch.tensor(xs, dtype=torch.float32, device=device)\n",
        "    ys = torch.tensor(ys, dtype=torch.float32, device=device)\n",
        "\n",
        "    return xs, ys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_ILK5ksYU44z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def data_fragmenter(df: pd.DataFrame, device=\"cpu\"):\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    df_fundamental = df[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "    df_mavg = df[[\"EMA_12\", \"EMA_26\"]]\n",
        "    df_mi = df[[\"MACD\", \"Signal\", \"RSI\", \"CCI\"]]\n",
        "    df_adx = df[[\"ADX\"]]\n",
        "\n",
        "    # normalize\n",
        "    df_fundamental = scaler.fit_transform(df_fundamental)\n",
        "    df_mavg = scaler.fit_transform(df_mavg)\n",
        "    df_mi = scaler.fit_transform(df_mi)\n",
        "    df_adx = scaler.fit_transform(df_adx)\n",
        "\n",
        "    fundamental_x, fundamental_y = data_sequencer(df_fundamental, 30, device=device)\n",
        "    mavg_x, mavg_y = data_sequencer(df_mavg, 30, device=device)\n",
        "    mi_x, mi_y = data_sequencer(df_mi, 30, device=device)\n",
        "    adx_x, adx_y = data_sequencer(df_adx, 30, device=device)\n",
        "\n",
        "    return fundamental_x, fundamental_y, mavg_x, mavg_y, mi_x, mi_y, adx_x, adx_y\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"./stocks_data/AAPL_data.csv\")\n",
        "fundamental_x, fundamental_y, mavg_x, mavg_y, mi_x, mi_y, adx_x, adx_y = data_fragmenter(df=df, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SZfG-KqNU44z"
      },
      "outputs": [],
      "source": [
        "## Make LSTM that can adapt to shape of data\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class LSTMv1(nn.Module):\n",
        "    def __init__(self, input_features, hidden_features, num_layers, output_features, device=\"cpu\"):\n",
        "        super().__init__()\n",
        "        self.hidden_features = hidden_features\n",
        "        self.num_layers = num_layers\n",
        "        self.device = device\n",
        "\n",
        "        self.lstm = nn.LSTM(input_features, hidden_features, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_features, output_features)\n",
        "        self.to(device=device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_features, device=self.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_features, device=self.device)\n",
        "\n",
        "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out)\n",
        "        return out[:, -1, :]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FIlN04txU440"
      },
      "outputs": [],
      "source": [
        "# INPUT_FEATURES = len(X_train[0, 0, :])\n",
        "# HIDDEN_FEATURES = 30\n",
        "# NUM_LAYERS = 3\n",
        "# OUTPUT_FEATURES = len(y_train[0, :])\n",
        "\n",
        "model_fundamental = LSTMv1(len(fundamental_x[0, 0, :]), hidden_features=128, num_layers=3, output_features=len(fundamental_y[0, :]), device=device)\n",
        "model_mavg = LSTMv1(len(mavg_x[0, 0, :]), hidden_features=128, num_layers=3, output_features=len(mavg_y[0, :]), device=device)\n",
        "model_mi = LSTMv1(len(mi_x[0, 0, :]), hidden_features=128, num_layers=3, output_features=len(mi_y[0, :]), device=device)\n",
        "model_adx = LSTMv1(len(adx_x[0, 0, :]), hidden_features=128, num_layers=3, output_features=len(adx_y[0, :]), device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGJ3lFgwU440",
        "outputId": "149b65f3-1e86-44a8-8989-f184254cd04f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(LSTMv1(\n",
              "   (lstm): LSTM(5, 128, num_layers=3, batch_first=True)\n",
              "   (fc): Linear(in_features=128, out_features=5, bias=True)\n",
              " ),\n",
              " LSTMv1(\n",
              "   (lstm): LSTM(2, 128, num_layers=3, batch_first=True)\n",
              "   (fc): Linear(in_features=128, out_features=2, bias=True)\n",
              " ),\n",
              " LSTMv1(\n",
              "   (lstm): LSTM(4, 128, num_layers=3, batch_first=True)\n",
              "   (fc): Linear(in_features=128, out_features=4, bias=True)\n",
              " ),\n",
              " LSTMv1(\n",
              "   (lstm): LSTM(1, 128, num_layers=3, batch_first=True)\n",
              "   (fc): Linear(in_features=128, out_features=1, bias=True)\n",
              " ))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_fundamental, model_mavg, model_mi, model_adx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lnwTG8apU440"
      },
      "outputs": [],
      "source": [
        "fundamental_loss_fn = nn.MSELoss().to(device)\n",
        "mavg_loss_fn = nn.MSELoss().to(device)\n",
        "mi_loss_fn = nn.MSELoss().to(device)\n",
        "adx_loss_fn = nn.MSELoss().to(device)\n",
        "\n",
        "optimizer_fundamental = torch.optim.Adam(params=model_fundamental.parameters(), lr=0.0001)\n",
        "optimizer_mavg = torch.optim.Adam(params=model_mavg.parameters(), lr=0.0001)\n",
        "optimizer_mi = torch.optim.Adam(params=model_mi.parameters(), lr=0.0001)\n",
        "optimizer_adx = torch.optim.Adam(params=model_adx.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "enbfMYmwU441",
        "outputId": "ec6d50ae-943f-4b29-a8e8-909c60fd0743"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'JPM_data.csv'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Alternate training\n",
        "import random\n",
        "import os\n",
        "file = random.choice(os.listdir(\"./stocks_data\"))\n",
        "file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXV7Jb-7U441"
      },
      "source": [
        "1. Pick a random file\n",
        "2. read csv data as df\n",
        "3. process df with data_fragmenter()\n",
        "4. provide inputs to model\n",
        "5. train certain epochs(10) with data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_y_i2upU441",
        "outputId": "86d5d7c1-b96d-4ae1-c5f6-c5f65b7a0ff0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nimport random, os\\nimport pandas as pd\\nimport torch\\ntotal_files = 30 * 200\\n\\nfor a_file in range(total_files):\\n    # pick a random file from dir\\n    file = random.choice(os.listdir(\"./stocks_data\"))\\n    if file.endswith(\".csv\"):\\n        # read csv file\\n        df = pd.read_csv(\"./stocks_data/\" + file)\\n        fundamental_x, fundamental_y, mavg_x, mavg_y, mi_x, mi_y, adx_x, adx_y = data_fragmenter(df=df, device=device)\\n\\n        ## training loop\\n        epoch = True\\n        # used while loop just to pretend as training loop\\n        while epoch:\\n            ## forward pass\\n            y_fundamental_pred = model_fundamental(fundamental_x)\\n            y_mavg_pred = model_mavg(mavg_x)\\n            y_mi_pred = model_mi(mi_x)\\n            y_adx_pred = model_adx(adx_x)\\n\\n            ## calculate the loss\\n            loss_fundamental = fundamental_loss_fn(y_fundamental_pred, fundamental_y)\\n            loss_mavg = mavg_loss_fn(y_mavg_pred, mavg_y)\\n            loss_mi = mi_loss_fn(y_mi_pred, mi_y)\\n            loss_adx = adx_loss_fn(y_adx_pred, adx_y)\\n\\n            ## optimizer sero grad\\n            optimizer_fundamental.zero_grad()\\n            optimizer_mavg.zero_grad()\\n            optimizer_mi.zero_grad()\\n            optimizer_adx.zero_grad()\\n\\n            ## loss backward (backpropagation)\\n            loss_fundamental.backward()\\n            loss_mavg.backward()\\n            loss_mi.backward()\\n            loss_adx.backward()\\n\\n            ## optimzer step (gradient descent)\\n            optimizer_fundamental.step()\\n            optimizer_mavg.step()\\n            optimizer_mi.step()\\n            optimizer_adx.step()\\n\\n            epoch = False\\n\\n        if a_file % 100 == 0:\\n            print(f\"Fundamental Model -> Epoch: {a_file} | Loss: {loss_fundamental}\")\\n            print(f\"MAVG Model -> Epoch: {a_file} | Loss: {loss_mavg}\")\\n            print(f\"MI Model -> Epoch: {a_file} | Loss: {loss_mi}\")\\n            print(f\"ADX Model -> Epoch: {a_file} | Loss: {loss_adx}\")\\n            print()\\n'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "import random, os\n",
        "import pandas as pd\n",
        "import torch\n",
        "total_files = 30 * 200\n",
        "\n",
        "for a_file in range(total_files):\n",
        "    # pick a random file from dir\n",
        "    file = random.choice(os.listdir(\"./stocks_data\"))\n",
        "    if file.endswith(\".csv\"):\n",
        "        # read csv file\n",
        "        df = pd.read_csv(\"./stocks_data/\" + file)\n",
        "        fundamental_x, fundamental_y, mavg_x, mavg_y, mi_x, mi_y, adx_x, adx_y = data_fragmenter(df=df, device=device)\n",
        "\n",
        "        ## training loop\n",
        "        epoch = True\n",
        "        # used while loop just to pretend as training loop\n",
        "        while epoch:\n",
        "            ## forward pass\n",
        "            y_fundamental_pred = model_fundamental(fundamental_x)\n",
        "            y_mavg_pred = model_mavg(mavg_x)\n",
        "            y_mi_pred = model_mi(mi_x)\n",
        "            y_adx_pred = model_adx(adx_x)\n",
        "\n",
        "            ## calculate the loss\n",
        "            loss_fundamental = fundamental_loss_fn(y_fundamental_pred, fundamental_y)\n",
        "            loss_mavg = mavg_loss_fn(y_mavg_pred, mavg_y)\n",
        "            loss_mi = mi_loss_fn(y_mi_pred, mi_y)\n",
        "            loss_adx = adx_loss_fn(y_adx_pred, adx_y)\n",
        "\n",
        "            ## optimizer sero grad\n",
        "            optimizer_fundamental.zero_grad()\n",
        "            optimizer_mavg.zero_grad()\n",
        "            optimizer_mi.zero_grad()\n",
        "            optimizer_adx.zero_grad()\n",
        "\n",
        "            ## loss backward (backpropagation)\n",
        "            loss_fundamental.backward()\n",
        "            loss_mavg.backward()\n",
        "            loss_mi.backward()\n",
        "            loss_adx.backward()\n",
        "\n",
        "            ## optimzer step (gradient descent)\n",
        "            optimizer_fundamental.step()\n",
        "            optimizer_mavg.step()\n",
        "            optimizer_mi.step()\n",
        "            optimizer_adx.step()\n",
        "\n",
        "            epoch = False\n",
        "\n",
        "        if a_file % 100 == 0:\n",
        "            print(f\"Fundamental Model -> Epoch: {a_file} | Loss: {loss_fundamental}\")\n",
        "            print(f\"MAVG Model -> Epoch: {a_file} | Loss: {loss_mavg}\")\n",
        "            print(f\"MI Model -> Epoch: {a_file} | Loss: {loss_mi}\")\n",
        "            print(f\"ADX Model -> Epoch: {a_file} | Loss: {loss_adx}\")\n",
        "            print()\n",
        "\"\"\"\n",
        "\n",
        "## working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WrlQqDzbU442"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nPATH = \"/content/models\"\\n\\n# Save each model\\'s state dictionary to a separate file\\ntorch.save(model_fundamental.state_dict(), f=os.path.join(PATH, \"model_fundamental.pth\"))\\ntorch.save(model_mavg.state_dict(), os.path.join(PATH, \"model_mavg.pth\"))\\ntorch.save(model_mi.state_dict(), os.path.join(PATH, \"model_mi.pth\"))\\ntorch.save(model_adx.state_dict(), os.path.join(PATH, \"model_adx.pth\"))'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "PATH = \"/content/models\"\n",
        "\n",
        "# Save each model's state dictionary to a separate file\n",
        "torch.save(model_fundamental.state_dict(), f=os.path.join(PATH, \"model_fundamental.pth\"))\n",
        "torch.save(model_mavg.state_dict(), os.path.join(PATH, \"model_mavg.pth\"))\n",
        "torch.save(model_mi.state_dict(), os.path.join(PATH, \"model_mi.pth\"))\n",
        "torch.save(model_adx.state_dict(), os.path.join(PATH, \"model_adx.pth\"))\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_fundamental = LSTMv1(input_features=5, hidden_features=128, num_layers=3, output_features=5, device=device)\n",
        "model_mavg = LSTMv1(input_features=2, hidden_features=128, num_layers=3, output_features=2, device=device)\n",
        "model_mi = LSTMv1(input_features=4, hidden_features=128, num_layers=3, output_features=4, device=device)\n",
        "model_adx = LSTMv1(input_features=1, hidden_features=128, num_layers=3, output_features=1, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## load saved models\n",
        "model_fundamental.load_state_dict(torch.load(\"./models/model_fundamental.pth\", weights_only=True, map_location=torch.device(device)))\n",
        "model_mavg.load_state_dict(torch.load(\"./models/model_mavg.pth\", weights_only=True, map_location=torch.device(device)))\n",
        "model_mi.load_state_dict(torch.load(\"./models/model_mi.pth\", weights_only=True, map_location=torch.device(device)))\n",
        "model_adx.load_state_dict(torch.load(\"./models/model_adx.pth\", weights_only=True, map_location=torch.device(device)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fundamental Model -> Epoch: 0 | Loss: 0.0016467742389068007\n",
            "MAVG Model -> Epoch: 0 | Loss: 0.00016547167615499347\n",
            "MI Model -> Epoch: 0 | Loss: 0.003551539033651352\n",
            "ADX Model -> Epoch: 0 | Loss: 0.00032433532760478556\n",
            "\n",
            "Fundamental Model -> Epoch: 20 | Loss: 0.0016467742389068007\n",
            "MAVG Model -> Epoch: 20 | Loss: 0.00016547167615499347\n",
            "MI Model -> Epoch: 20 | Loss: 0.003551539033651352\n",
            "ADX Model -> Epoch: 20 | Loss: 0.00032433532760478556\n",
            "\n",
            "Fundamental Model -> Epoch: 40 | Loss: 0.0016467742389068007\n",
            "MAVG Model -> Epoch: 40 | Loss: 0.00016547167615499347\n",
            "MI Model -> Epoch: 40 | Loss: 0.003551539033651352\n",
            "ADX Model -> Epoch: 40 | Loss: 0.00032433532760478556\n",
            "\n",
            "Fundamental Model -> Epoch: 60 | Loss: 0.0016467742389068007\n",
            "MAVG Model -> Epoch: 60 | Loss: 0.00016547167615499347\n",
            "MI Model -> Epoch: 60 | Loss: 0.003551539033651352\n",
            "ADX Model -> Epoch: 60 | Loss: 0.00032433532760478556\n",
            "\n",
            "Fundamental Model -> Epoch: 80 | Loss: 0.0016467742389068007\n",
            "MAVG Model -> Epoch: 80 | Loss: 0.00016547167615499347\n",
            "MI Model -> Epoch: 80 | Loss: 0.003551539033651352\n",
            "ADX Model -> Epoch: 80 | Loss: 0.00032433532760478556\n",
            "\n",
            "Fundamental Model -> Epoch: 100 | Loss: 0.0016467742389068007\n",
            "MAVG Model -> Epoch: 100 | Loss: 0.00016547167615499347\n",
            "MI Model -> Epoch: 100 | Loss: 0.003551539033651352\n",
            "ADX Model -> Epoch: 100 | Loss: 0.00032433532760478556\n",
            "\n",
            "Fundamental Model -> Epoch: 120 | Loss: 0.0016467742389068007\n",
            "MAVG Model -> Epoch: 120 | Loss: 0.00016547167615499347\n",
            "MI Model -> Epoch: 120 | Loss: 0.003551539033651352\n",
            "ADX Model -> Epoch: 120 | Loss: 0.00032433532760478556\n",
            "\n",
            "Fundamental Model -> Epoch: 140 | Loss: 0.0016467742389068007\n",
            "MAVG Model -> Epoch: 140 | Loss: 0.00016547167615499347\n",
            "MI Model -> Epoch: 140 | Loss: 0.003551539033651352\n",
            "ADX Model -> Epoch: 140 | Loss: 0.00032433532760478556\n",
            "\n",
            "Fundamental Model -> Epoch: 160 | Loss: 0.0016467742389068007\n",
            "MAVG Model -> Epoch: 160 | Loss: 0.00016547167615499347\n",
            "MI Model -> Epoch: 160 | Loss: 0.003551539033651352\n",
            "ADX Model -> Epoch: 160 | Loss: 0.00032433532760478556\n",
            "\n",
            "Fundamental Model -> Epoch: 180 | Loss: 0.0016467742389068007\n",
            "MAVG Model -> Epoch: 180 | Loss: 0.00016547167615499347\n",
            "MI Model -> Epoch: 180 | Loss: 0.003551539033651352\n",
            "ADX Model -> Epoch: 180 | Loss: 0.00032433532760478556\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## training loop\n",
        "total_epochs = 200\n",
        "df = pd.read_csv(\"DJI_data.csv\")\n",
        "fundamental_x, fundamental_y, mavg_x, mavg_y, mi_x, mi_y, adx_x, adx_y = data_fragmenter(df=df, device=device)\n",
        "\n",
        "for epoch in range(total_epochs):\n",
        "    ## forward pass\n",
        "    y_fundamental_pred = model_fundamental(fundamental_x)\n",
        "    y_mavg_pred = model_mavg(mavg_x)\n",
        "    y_mi_pred = model_mi(mi_x)\n",
        "    y_adx_pred = model_adx(adx_x)\n",
        "\n",
        "    ## calculate the loss\n",
        "    loss_fundamental = fundamental_loss_fn(y_fundamental_pred, fundamental_y)\n",
        "    loss_mavg = mavg_loss_fn(y_mavg_pred, mavg_y)\n",
        "    loss_mi = mi_loss_fn(y_mi_pred, mi_y)\n",
        "    loss_adx = adx_loss_fn(y_adx_pred, adx_y)\n",
        "\n",
        "    ## optimizer sero grad\n",
        "    optimizer_fundamental.zero_grad()\n",
        "    optimizer_mavg.zero_grad()\n",
        "    optimizer_mi.zero_grad()\n",
        "    optimizer_adx.zero_grad()\n",
        "\n",
        "    ## loss backward (backpropagation)\n",
        "    loss_fundamental.backward()\n",
        "    loss_mavg.backward()\n",
        "    loss_mi.backward()\n",
        "    loss_adx.backward()\n",
        "\n",
        "    ## optimzer step (gradient descent)\n",
        "    optimizer_fundamental.step()\n",
        "    optimizer_mavg.step()\n",
        "    optimizer_mi.step()\n",
        "    optimizer_adx.step()\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"Fundamental Model -> Epoch: {epoch} | Loss: {loss_fundamental}\")\n",
        "        print(f\"MAVG Model -> Epoch: {epoch} | Loss: {loss_mavg}\")\n",
        "        print(f\"MI Model -> Epoch: {epoch} | Loss: {loss_mi}\")\n",
        "        print(f\"ADX Model -> Epoch: {epoch} | Loss: {loss_adx}\")\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "## saving models\n",
        "PATH = \"./models\"\n",
        "torch.save(model_fundamental.state_dict(), f=os.path.join(PATH, \"model_fundamental.pth\"))\n",
        "torch.save(model_mavg.state_dict(), os.path.join(PATH, \"model_mavg.pth\"))\n",
        "torch.save(model_mi.state_dict(), os.path.join(PATH, \"model_mi.pth\"))\n",
        "torch.save(model_adx.state_dict(), os.path.join(PATH, \"model_adx.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E1P-1JvmINi",
        "outputId": "878c1425-540b-46bf-9376-47a8f6dbfae5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: models/ (stored 0%)\n",
            "  adding: models/model_adx.pth (deflated 8%)\n",
            "  adding: models/model_mavg.pth (deflated 8%)\n",
            "  adding: models/model_fundamental.pth (deflated 8%)\n",
            "  adding: models/model_mi.pth (deflated 8%)\n"
          ]
        }
      ],
      "source": [
        "# !zip -r models.zip \"./models\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUq84sH3omHM"
      },
      "source": [
        "### **Building Trading Env** (from scratch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plan:\n",
        "1. Make Env for trading\n",
        "2. Add LSTM predictions function and add predictions to observation space\n",
        "3. Also, add a function to calculate metrics: Sharpe Ratio and Sorinto Ratio\n",
        "4. In training enable `tensorboard logits`\n",
        "5. Use PyPlot (better than matplotlib)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch    # for loading LSTM models\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3 import PPO\n",
        "import random\n",
        "from stable_baselines3.common.utils import get_schedule_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "## hyper parameters\n",
        "MAX_ACCOUNT_BALANCE = 2147483647\n",
        "MAX_NUM_SHARES = 2147483647\n",
        "MAX_SHARE_PRICE = 5000\n",
        "MAX_STEPS = 100000\n",
        "INITIAL_ACCOUNT_BALANCE = 1000000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def data_sequencer(data: torch.Tensor, sequence_len: int, device=\"cpu\"):\n",
        "    xs = []\n",
        "    ys = []\n",
        "\n",
        "    for i in range(len(data) - sequence_len):\n",
        "        xs.append(data[i: i+sequence_len])\n",
        "        ys.append(data[i+sequence_len])\n",
        "\n",
        "    xs = np.array(xs)\n",
        "    ys = np.array(ys)\n",
        "\n",
        "    xs = torch.tensor(xs, dtype=torch.float32, device=device)\n",
        "    ys = torch.tensor(ys, dtype=torch.float32, device=device)\n",
        "\n",
        "    return xs, ys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def data_fragmenter(df: pd.DataFrame, device=\"cpu\"):\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    df_fundamental = df[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "    df_mavg = df[[\"EMA_12\", \"EMA_26\"]]\n",
        "    df_mi = df[[\"MACD\", \"Signal\", \"RSI\", \"CCI\"]]\n",
        "    df_adx = df[[\"ADX\"]]\n",
        "\n",
        "    # normalize\n",
        "    df_fundamental = scaler.fit_transform(df_fundamental)\n",
        "    df_mavg = scaler.fit_transform(df_mavg)\n",
        "    df_mi = scaler.fit_transform(df_mi)\n",
        "    df_adx = scaler.fit_transform(df_adx)\n",
        "\n",
        "    fundamental_x, fundamental_y = data_sequencer(df_fundamental, 30, device=device)\n",
        "    mavg_x, mavg_y = data_sequencer(df_mavg, 30, device=device)\n",
        "    mi_x, mi_y = data_sequencer(df_mi, 30, device=device)\n",
        "    adx_x, adx_y = data_sequencer(df_adx, 30, device=device)\n",
        "\n",
        "    return fundamental_x, fundamental_y, mavg_x, mavg_y, mi_x, mi_y, adx_x, adx_y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class StockTradingEnv(gym.Env):\n",
        "    def __init__(self, df, render_mode=\"human\"):\n",
        "        super().__init__()\n",
        "\n",
        "        self.df = df\n",
        "        self.render_mode = render_mode\n",
        "        self.reward_range = (0, MAX_ACCOUNT_BALANCE)\n",
        "\n",
        "        self.action_space = spaces.Box(low=np.array([0, 0]), high=np.array([3, 1]), dtype=np.float32)\n",
        "\n",
        "        self.balance = INITIAL_ACCOUNT_BALANCE\n",
        "        self.net_worth = INITIAL_ACCOUNT_BALANCE\n",
        "        self.max_net_worth = INITIAL_ACCOUNT_BALANCE\n",
        "        self.shares_held = 0\n",
        "        self.cost_basis = 0\n",
        "        self.total_shares_sold = 0\n",
        "        self.total_sales_value = 0\n",
        "        self.rewards = []\n",
        "        self.current_step = 0\n",
        "        self.risk_free_rate = 0.00\n",
        "        self.net_worth_log = []\n",
        "        self.returns = []\n",
        "        self.turbulence_threshold = 90\n",
        "        self.trade_count = 0\n",
        "\n",
        "        self.episode_sharpe_ratios = []\n",
        "        self.episode_sortino_ratios = []\n",
        "\n",
        "        sample_obs = self._next_observation()\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=sample_obs.shape, dtype=np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        prev_net_worth = self.net_worth\n",
        "        self._take_action(action)\n",
        "        self.current_step += 1\n",
        "\n",
        "        self.track_net_worth()\n",
        "\n",
        "        terminated = (self.net_worth <= 0) or (self.current_step >= len(self.df))\n",
        "        truncated  = (self.current_step >= MAX_STEPS)\n",
        "\n",
        "        reward = (self.net_worth - prev_net_worth) / INITIAL_ACCOUNT_BALANCE\n",
        "        drawdown = max(self.max_net_worth - self.net_worth, 0)\n",
        "        reward -= drawdown / self.max_net_worth * 0.1\n",
        "\n",
        "        self.rewards.append(reward)\n",
        "\n",
        "        step_return = (self.net_worth - prev_net_worth) / prev_net_worth\n",
        "        self.returns.append(step_return)\n",
        "\n",
        "        info = {\"net_worth_log\": self.net_worth_log.copy()}\n",
        "\n",
        "        if terminated or truncated:\n",
        "            returns = np.array(self.returns)\n",
        "            initial = INITIAL_ACCOUNT_BALANCE\n",
        "            final = self.net_worth\n",
        "            net_worth_log = self.net_worth_log\n",
        "\n",
        "            sharpe = self._calculate_sharpe(returns)\n",
        "            sortino = self._calculate_sortino(returns)\n",
        "            cumulative_return = self._calculate_cumulative_return(net_worth_log)\n",
        "            max_earning_rate = self._calculate_max_earning_rate(net_worth_log)\n",
        "            max_drawdown = self._calculate_max_drawdown(returns)\n",
        "            avg_profitability = self._calculate_average_profitability(returns)\n",
        "            max_pullback = self._calculate_max_pullback(net_worth_log)\n",
        "            avg_profit_per_trade = self._calculate_average_profitability_per_trade(initial, final, self.trade_count)\n",
        "\n",
        "            info.update({\n",
        "                \"sharpe_ratio\": sharpe,\n",
        "                \"sortino_ratio\": sortino,\n",
        "                \"cumulative_return\": cumulative_return,\n",
        "                \"max_earning_rate\": max_earning_rate,\n",
        "                \"max_drawdown\": max_drawdown,\n",
        "                \"average_profitability\": avg_profitability,\n",
        "                \"max_pullback\": max_pullback,\n",
        "                \"average_profitability_per_trade\": avg_profit_per_trade,\n",
        "                \"net_worth_log\": net_worth_log.copy()\n",
        "            })\n",
        "\n",
        "        obs = (\n",
        "            self._next_observation()\n",
        "            if not (terminated or truncated)\n",
        "            else np.zeros(self.observation_space.shape, dtype=np.float32)\n",
        "        )\n",
        "        return obs, reward, terminated, truncated, info\n",
        "\n",
        "\n",
        "    def _take_action(self, action):\n",
        "        current_price = random.uniform(self.df.loc[self.current_step, \"Open\"], self.df.loc[self.current_step, \"Close\"])\n",
        "        if np.isnan(current_price) or current_price <= 0:\n",
        "            current_price = 1e-6\n",
        "\n",
        "        turbulence = self._compute_turbulence()\n",
        "\n",
        "        if turbulence > self.turbulence_threshold:\n",
        "            action_type = 1\n",
        "            amount = 1.0\n",
        "            self.trade_count += 1\n",
        "            # if self.render_mode == \"human\":\n",
        "            #     print(f\"[TURBULENCE OVERRIDE] Step {self.current_step}: Turbulence {turbulence:.4f} > Threshold {self.turbulence_threshold:.4f}  Forcing SELL ALL\")\n",
        "        else:\n",
        "            action_type = int(np.clip(np.floor(action[0]), 0, 2))\n",
        "            amount = float(np.clip(action[1], 0, 1))\n",
        "            self.trade_count += 1\n",
        "\n",
        "        if action_type < 1:\n",
        "            total_possible = self.balance / current_price\n",
        "            shares_bought = int(total_possible * amount)\n",
        "            if shares_bought > 0:\n",
        "                prev_cost = self.cost_basis * self.shares_held\n",
        "                additional_cost = shares_bought * current_price\n",
        "                if self.balance >= additional_cost:\n",
        "                    self.balance -= additional_cost\n",
        "                    self.shares_held += shares_bought\n",
        "                    if self.shares_held > 0:\n",
        "                        self.cost_basis = (prev_cost + additional_cost) / self.shares_held\n",
        "\n",
        "        elif action_type < 2:\n",
        "            shares_sold = int(self.shares_held * amount)\n",
        "            shares_sold = min(shares_sold, self.shares_held)\n",
        "            self.balance += shares_sold * current_price\n",
        "            self.shares_held -= shares_sold\n",
        "            self.total_shares_sold += shares_sold\n",
        "            self.total_sales_value += shares_sold * current_price\n",
        "\n",
        "        self.shares_held = max(0, self.shares_held)\n",
        "        self.net_worth = self.balance + (self.shares_held * current_price)\n",
        "        self.max_net_worth = max(self.max_net_worth, self.net_worth)\n",
        "\n",
        "        if self.shares_held == 0:\n",
        "            self.cost_basis = 0\n",
        "\n",
        "    def _next_observation(self):\n",
        "        day_data = self.df.iloc[self.current_step]\n",
        "        frame = np.array([\n",
        "            day_data['Open'] / MAX_SHARE_PRICE,\n",
        "            day_data['High'] / MAX_SHARE_PRICE,\n",
        "            day_data['Low'] / MAX_SHARE_PRICE,\n",
        "            day_data['Close'] / MAX_SHARE_PRICE,\n",
        "            day_data['Volume'] / MAX_NUM_SHARES,\n",
        "            day_data['EMA_12'] / MAX_SHARE_PRICE,\n",
        "            day_data['EMA_26'] / MAX_SHARE_PRICE,\n",
        "            day_data['MACD'] / 100,\n",
        "            day_data['Signal'] / 100,\n",
        "            day_data['RSI'] / 100,\n",
        "            day_data['CCI'] / 200,\n",
        "            day_data['ADX'] / 100,\n",
        "            day_data['Sentiment Average'] / 1,\n",
        "        ])\n",
        "\n",
        "        attributes = np.array([\n",
        "            self.balance / MAX_ACCOUNT_BALANCE,\n",
        "            self.max_net_worth / MAX_ACCOUNT_BALANCE,\n",
        "            self.shares_held / MAX_NUM_SHARES,\n",
        "            self.cost_basis / MAX_SHARE_PRICE,\n",
        "            self.total_shares_sold / MAX_NUM_SHARES,\n",
        "            self.total_sales_value / (MAX_NUM_SHARES * MAX_SHARE_PRICE),\n",
        "        ])\n",
        "\n",
        "        fundamental_predictions, mavg_predictions, mi_predictions, adx_predictions = self._lstm_predictions()\n",
        "\n",
        "        predictions = np.concatenate([\n",
        "            fundamental_predictions, mavg_predictions, mi_predictions, adx_predictions\n",
        "        ])\n",
        "\n",
        "        obs = np.concatenate([frame, attributes, predictions])\n",
        "        return obs\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        if seed is not None:\n",
        "            np.random.seed(seed)\n",
        "            random.seed(seed)\n",
        "            torch.manual_seed(seed)\n",
        "\n",
        "        self.balance = INITIAL_ACCOUNT_BALANCE\n",
        "        self.net_worth = INITIAL_ACCOUNT_BALANCE\n",
        "        self.max_net_worth = INITIAL_ACCOUNT_BALANCE\n",
        "        self.shares_held = 0\n",
        "        self.cost_basis = 0\n",
        "        self.total_shares_sold = 0\n",
        "        self.total_sales_value = 0\n",
        "        self.rewards = []\n",
        "        self.net_worth_log = []\n",
        "        self.returns = []\n",
        "\n",
        "        self.track_net_worth()\n",
        "        self.current_step = random.randint(1, len(self.df.loc[:, \"Open\"].values) - 1)\n",
        "\n",
        "        return self._next_observation(), {}\n",
        "\n",
        "    def track_net_worth(self):\n",
        "        if not hasattr(self, \"net_worth_log\"):\n",
        "            self.net_worth_log = []\n",
        "        self.net_worth_log.append(self.net_worth)\n",
        "\n",
        "    def _lstm_predictions(self):\n",
        "        fundamental_data = self.df.loc[self.current_step, ['Open', 'High', 'Low', 'Close', 'Volume']].values\n",
        "        mavg_data = self.df.loc[self.current_step, ['EMA_12', 'EMA_26']].values\n",
        "        mi_data = self.df.loc[self.current_step, ['MACD', 'Signal', 'RSI', 'CCI']].values\n",
        "        adx_data = self.df.loc[self.current_step, ['ADX']].values\n",
        "\n",
        "        fundamental_data = torch.tensor(fundamental_data.astype(np.float32), dtype=torch.float32, device=device).view(1, 1, -1)\n",
        "        mavg_data = torch.tensor(mavg_data.astype(np.float32), dtype=torch.float32, device=device).view(1, 1, -1)\n",
        "        mi_data = torch.tensor(mi_data.astype(np.float32), dtype=torch.float32, device=device).view(1, 1, -1)\n",
        "        adx_data = torch.tensor(adx_data.astype(np.float32), dtype=torch.float32, device=device).view(1, 1, -1)\n",
        "\n",
        "        fundamental_predictions = np.clip(model_fundamental(fundamental_data).detach().cpu().numpy().flatten(), -1, 1)\n",
        "        mavg_predictions = np.clip(model_mavg(mavg_data).detach().cpu().numpy().flatten(), -1, 1)\n",
        "        mi_predictions = np.clip(model_mi(mi_data).detach().cpu().numpy().flatten(), -1, 1)\n",
        "        adx_predictions = np.clip(model_adx(adx_data).detach().cpu().numpy().flatten(), -1, 1)\n",
        "\n",
        "        return fundamental_predictions, mavg_predictions, mi_predictions, adx_predictions\n",
        "\n",
        "    def _compute_turbulence(self):\n",
        "        features = ['Close', 'Volume', 'MACD', 'Signal', 'RSI', 'CCI', 'ADX']\n",
        "\n",
        "        if self.current_step < 1:\n",
        "            return 0\n",
        "\n",
        "        try:\n",
        "            current_data = self.df.iloc[self.current_step][features].values.reshape(1, -1)\n",
        "            historical_data = self.df.iloc[:self.current_step][features].values\n",
        "\n",
        "            if len(historical_data) < 2:\n",
        "                return 0\n",
        "\n",
        "            mean_vector = np.mean(historical_data, axis=0)\n",
        "            cov_matrix = np.cov(historical_data, rowvar=False)\n",
        "            cov_inv = np.linalg.pinv(cov_matrix)\n",
        "\n",
        "            delta = current_data - mean_vector\n",
        "            turbulence = np.dot(np.dot(delta, cov_inv), delta.T).item()\n",
        "            return turbulence\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Turbulence calculation error: {e}\")\n",
        "            return 0\n",
        "\n",
        "    def _calculate_sharpe(self, returns, annualize=True):\n",
        "        returns = np.array(returns)\n",
        "        if len(returns) <= 1:\n",
        "            return 0.0\n",
        "        excess_returns = returns - (self.risk_free_rate / 252)\n",
        "        mean = np.mean(excess_returns)\n",
        "        std = np.std(excess_returns)\n",
        "        if std < 1e-6:\n",
        "            return 0.0\n",
        "        sharpe = mean / std\n",
        "        return sharpe * np.sqrt(252) if annualize else sharpe\n",
        "\n",
        "    def _calculate_sortino(self, returns, annualize=True):\n",
        "        returns = np.array(returns)\n",
        "        if len(returns) <= 1:\n",
        "            return 0.0\n",
        "        downside_returns = returns[returns < (self.risk_free_rate / 252)]\n",
        "        if len(downside_returns) == 0:\n",
        "            return 0.0\n",
        "        downside_std = np.std(downside_returns)\n",
        "        if downside_std < 1e-6:\n",
        "            return 0.0\n",
        "        expected_return = np.mean(returns)\n",
        "        sortino = (expected_return - (self.risk_free_rate / 252)) / downside_std\n",
        "        return sortino * np.sqrt(252) if annualize else sortino\n",
        "\n",
        "    def _calculate_cumulative_return(self, asset_values):\n",
        "        if len(asset_values) < 2 or asset_values[0] == 0:\n",
        "            return 0.0\n",
        "        return ((asset_values[-1] - asset_values[0]) / asset_values[0]) * 100\n",
        "\n",
        "    def _calculate_max_earning_rate(self, asset_values):\n",
        "        asset_values = np.array(asset_values)\n",
        "        if len(asset_values) < 2:\n",
        "            return 0.0\n",
        "        max_earning = max([\n",
        "            (asset_values[i] - asset_values[j]) / asset_values[j]\n",
        "            for i in range(len(asset_values))\n",
        "            for j in range(i)\n",
        "        ])\n",
        "        return max_earning * 100\n",
        "\n",
        "    def _calculate_max_drawdown(self, returns):\n",
        "        if len(returns) == 0:\n",
        "            return 0.0\n",
        "        cumulative_returns = np.cumprod(1 + np.array(returns))\n",
        "        peak = np.maximum.accumulate(cumulative_returns)\n",
        "        drawdowns = (cumulative_returns - peak) / peak\n",
        "        return np.min(drawdowns) * 100\n",
        "\n",
        "    def _calculate_average_profitability(self, returns):\n",
        "        if len(returns) == 0:\n",
        "            return 0.0\n",
        "        return np.mean(returns) * 100\n",
        "\n",
        "    def _calculate_max_pullback(self, asset_values):\n",
        "        if len(asset_values) < 2:\n",
        "            return 0.0\n",
        "        max_pullback = 0.0\n",
        "        peak = asset_values[0]\n",
        "        for value in asset_values:\n",
        "            peak = max(peak, value)\n",
        "            drawdown = (peak - value) / peak\n",
        "            max_pullback = max(max_pullback, drawdown)\n",
        "        return max_pullback * 100\n",
        "\n",
        "    def _calculate_average_profitability_per_trade(self, initial_value, final_value, num_trades):\n",
        "        if num_trades == 0:\n",
        "            return 0.0\n",
        "        return ((final_value - initial_value) / num_trades)\n",
        "\n",
        "\n",
        "    def render(self, mode=\"human\", close=False):\n",
        "        mode = mode if mode is not None else self.render_mode\n",
        "        if self.render_mode == \"human\":\n",
        "            profit = self.net_worth - INITIAL_ACCOUNT_BALANCE\n",
        "            print(f'Step: {self.current_step}')\n",
        "            print(f'Balance: {self.balance}')\n",
        "            print(f'Shares held: {self.shares_held} (Total sold: {self.total_shares_sold})')\n",
        "            print(f'Avg cost for held shares: {self.cost_basis} (Total sales value: {self.total_sales_value})')\n",
        "            print(f'Net worth: {self.net_worth} (Max net worth: {self.max_net_worth})')\n",
        "            print(f'Profit: {profit}')\n",
        "        elif self.render_mode == \"rgb_array\":\n",
        "            return np.zeros((400, 600, 3), dtype=np.uint8)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported render mode: {self.render_mode}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"DJI_data.csv\")\n",
        "fundamental_x, fundamental_y, mavg_x, mavg_y, mi_x, mi_y, adx_x, adx_y = data_fragmenter(df=df, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class LSTMv1(nn.Module):\n",
        "    def __init__(self, input_features, hidden_features, num_layers, output_features, device=\"cpu\"):\n",
        "        super().__init__()\n",
        "        self.hidden_features = hidden_features\n",
        "        self.num_layers = num_layers\n",
        "        self.device = device\n",
        "\n",
        "        self.lstm = nn.LSTM(input_features, hidden_features, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_features, output_features)\n",
        "        self.to(device=device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_features, device=self.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_features, device=self.device)\n",
        "\n",
        "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out)\n",
        "        return out[:, -1, :]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_fundamental = LSTMv1(len(fundamental_x[0, 0, :]), hidden_features=128, num_layers=3, output_features=len(fundamental_y[0, :]), device=device)\n",
        "model_mavg = LSTMv1(len(mavg_x[0, 0, :]), hidden_features=128, num_layers=3, output_features=len(mavg_y[0, :]), device=device)\n",
        "model_mi = LSTMv1(len(mi_x[0, 0, :]), hidden_features=128, num_layers=3, output_features=len(mi_y[0, :]), device=device)\n",
        "model_adx = LSTMv1(len(adx_x[0, 0, :]), hidden_features=128, num_layers=3, output_features=len(adx_y[0, :]), device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## load saved models\n",
        "model_fundamental.load_state_dict(torch.load(\"./models/model_fundamental.pth\", weights_only=True, map_location=torch.device(device)))\n",
        "model_mavg.load_state_dict(torch.load(\"./models/model_mavg.pth\", weights_only=True, map_location=torch.device(device)))\n",
        "model_mi.load_state_dict(torch.load(\"./models/model_mi.pth\", weights_only=True, map_location=torch.device(device)))\n",
        "model_adx.load_state_dict(torch.load(\"./models/model_adx.pth\", weights_only=True, map_location=torch.device(device)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([1732, 30, 5]), torch.Size([1732, 5]))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fundamental_x.shape, fundamental_y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # use for initial training only\n",
        "# import os\n",
        "\n",
        "# env = DummyVecEnv([lambda: StockTradingEnv(df=df)])\n",
        "# env.seed(0)\n",
        "\n",
        "# # models_dir = \"models/PPO\"\n",
        "# # logdir = \"logs\"\n",
        "\n",
        "# # if not os.path.exists(models_dir):\n",
        "# #     os.makedirs(models_dir)\n",
        "\n",
        "# # if not os.path.exists(logdir):\n",
        "# #     os.makedirs(logdir)\n",
        "\n",
        "# model = PPO(\"MlpPolicy\", env,\n",
        "#             n_steps=8192,\n",
        "#             batch_size=2048,\n",
        "#             learning_rate=get_schedule_fn(0.0003),\n",
        "#             ent_coef=0.01,\n",
        "#             vf_coef=0.5,\n",
        "#             clip_range=0.2,\n",
        "#             clip_range_vf=None,\n",
        "#             n_epochs=10,\n",
        "#             gamma=0.99,\n",
        "#             gae_lambda=0.95,\n",
        "#             max_grad_norm=0.5,\n",
        "#             target_kl=0.01,\n",
        "#             verbose=1, tensorboard_log=\"./updated_logs/PPO_5\")\n",
        "\n",
        "# TIMESTEPS = 1500000\n",
        "# iters = 0\n",
        "# for i in range(1):\n",
        "#     iters += 1\n",
        "#     model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False)\n",
        "#     model.save(\"./models/PPO/7000000.zip\")\n",
        "# ## change this for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "path = \"DJI_data.csv\"\n",
        "df = pd.read_csv(path)\n",
        "company_name = os.path.basename(path).split(\"_\")[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ## re-training the model on existing parameters\n",
        "# from stable_baselines3.common.logger import configure\n",
        "# model_path = \"./models/PPO/13000000.zip\"\n",
        "# env = DummyVecEnv([lambda: StockTradingEnv(df=df)])\n",
        "# model = PPO.load(model_path, env=env)\n",
        "# new_logger = configure(\"./updated_logs/PPO_9/PPO_0\", [\"tensorboard\"])\n",
        "# # model.set_logger(new_logger)\n",
        "# TIMESTEPS = 1000000\n",
        "# model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False)\n",
        "# model.save(\"./models/PPO/14000000.zip\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from stable_baselines3 import PPO\n",
        "# from stable_baselines3.common.utils import get_schedule_fn\n",
        "# import os\n",
        "\n",
        "# env = DummyVecEnv([lambda: StockTradingEnv(df=df)])\n",
        "\n",
        "# old_model = PPO.load(\"./models/PPO/13000000.zip\")\n",
        "\n",
        "# logdir = \"./updated_logs/PPO_10\"\n",
        "\n",
        "# if not os.path.exists(logdir):\n",
        "#     os.makedirs(logdir)\n",
        "\n",
        "# new_model = PPO(\"MlpPolicy\", env,\n",
        "#                 n_steps=8192,\n",
        "#                 batch_size=2048,\n",
        "#                 learning_rate=get_schedule_fn(3e-5 * 0.95),\n",
        "#                 ent_coef=0.01,\n",
        "#                 vf_coef=0.7,\n",
        "#                 clip_range=get_schedule_fn(0.2),\n",
        "#                 clip_range_vf=None,\n",
        "#                 n_epochs=5,\n",
        "#                 gamma=0.985,\n",
        "#                 gae_lambda=0.9,\n",
        "#                 max_grad_norm=0.4,\n",
        "#                 target_kl=0.015,\n",
        "#                 verbose=1, tensorboard_log=logdir\n",
        "#             )\n",
        "\n",
        "# new_model.policy.load_state_dict(old_model.policy.state_dict())\n",
        "\n",
        "# new_model.learn(total_timesteps=2500000, reset_num_timesteps=False)\n",
        "# new_model.save(\"./models/PPO/14000000.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "## replicate model with some parameter tuning\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.utils import get_schedule_fn\n",
        "import os\n",
        "\n",
        "env = DummyVecEnv([lambda: StockTradingEnv(df=df)])\n",
        "\n",
        "old_model = PPO.load(\"./models/PPO/14000000.zip\")\n",
        "\n",
        "logdir = \"./updated_logs/PPO_10\"\n",
        "\n",
        "if not os.path.exists(logdir):\n",
        "    os.makedirs(logdir)\n",
        "\n",
        "new_model = PPO(\"MlpPolicy\", env,\n",
        "                n_steps=2048,\n",
        "                batch_size=128,\n",
        "                learning_rate=get_schedule_fn(3e-5 * 0.95),\n",
        "                ent_coef=0.01,\n",
        "                vf_coef=0.7,\n",
        "                clip_range=get_schedule_fn(0.2),\n",
        "                clip_range_vf=None,\n",
        "                n_epochs=5,\n",
        "                gamma=0.985,\n",
        "                gae_lambda=0.9,\n",
        "                max_grad_norm=0.4,\n",
        "                target_kl=0.015,\n",
        "                verbose=0\n",
        "            )\n",
        "\n",
        "new_model.policy.load_state_dict(old_model.policy.state_dict())\n",
        "new_model.save(\"./models/PPO/14M_02.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "RL_project",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
